{
  "best_metric": 0.9033841360345001,
  "best_model_checkpoint": "/content/drive/MyDrive/iJudge/checkpoints/checkpoint-9300",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 9300,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005377789728421619,
      "grad_norm": 1.4014203548431396,
      "learning_rate": 2.688172043010753e-07,
      "loss": 1.3983,
      "step": 10
    },
    {
      "epoch": 0.010755579456843238,
      "grad_norm": 1.292958378791809,
      "learning_rate": 5.376344086021506e-07,
      "loss": 1.4032,
      "step": 20
    },
    {
      "epoch": 0.016133369185264857,
      "grad_norm": 1.3887827396392822,
      "learning_rate": 8.064516129032258e-07,
      "loss": 1.3876,
      "step": 30
    },
    {
      "epoch": 0.021511158913686476,
      "grad_norm": 1.7683461904525757,
      "learning_rate": 1.0752688172043011e-06,
      "loss": 1.3888,
      "step": 40
    },
    {
      "epoch": 0.026888948642108095,
      "grad_norm": 1.5649691820144653,
      "learning_rate": 1.3440860215053763e-06,
      "loss": 1.3883,
      "step": 50
    },
    {
      "epoch": 0.032266738370529714,
      "grad_norm": 1.6248472929000854,
      "learning_rate": 1.6129032258064516e-06,
      "loss": 1.3859,
      "step": 60
    },
    {
      "epoch": 0.03764452809895133,
      "grad_norm": 1.6858974695205688,
      "learning_rate": 1.8817204301075267e-06,
      "loss": 1.3827,
      "step": 70
    },
    {
      "epoch": 0.04302231782737295,
      "grad_norm": 1.3663082122802734,
      "learning_rate": 2.1505376344086023e-06,
      "loss": 1.3777,
      "step": 80
    },
    {
      "epoch": 0.04840010755579457,
      "grad_norm": 1.3492906093597412,
      "learning_rate": 2.4193548387096776e-06,
      "loss": 1.3884,
      "step": 90
    },
    {
      "epoch": 0.05377789728421619,
      "grad_norm": 1.809045672416687,
      "learning_rate": 2.6881720430107525e-06,
      "loss": 1.3773,
      "step": 100
    },
    {
      "epoch": 0.059155687012637806,
      "grad_norm": 1.1675750017166138,
      "learning_rate": 2.956989247311828e-06,
      "loss": 1.3714,
      "step": 110
    },
    {
      "epoch": 0.06453347674105943,
      "grad_norm": 1.6298826932907104,
      "learning_rate": 3.225806451612903e-06,
      "loss": 1.3541,
      "step": 120
    },
    {
      "epoch": 0.06991126646948104,
      "grad_norm": 1.5431700944900513,
      "learning_rate": 3.4946236559139785e-06,
      "loss": 1.346,
      "step": 130
    },
    {
      "epoch": 0.07528905619790266,
      "grad_norm": 1.3209342956542969,
      "learning_rate": 3.7634408602150534e-06,
      "loss": 1.3696,
      "step": 140
    },
    {
      "epoch": 0.08066684592632428,
      "grad_norm": 1.391414761543274,
      "learning_rate": 4.032258064516129e-06,
      "loss": 1.3565,
      "step": 150
    },
    {
      "epoch": 0.0860446356547459,
      "grad_norm": 1.5922373533248901,
      "learning_rate": 4.3010752688172045e-06,
      "loss": 1.3453,
      "step": 160
    },
    {
      "epoch": 0.09142242538316751,
      "grad_norm": 1.4964913129806519,
      "learning_rate": 4.56989247311828e-06,
      "loss": 1.332,
      "step": 170
    },
    {
      "epoch": 0.09680021511158914,
      "grad_norm": 1.4378290176391602,
      "learning_rate": 4.838709677419355e-06,
      "loss": 1.3402,
      "step": 180
    },
    {
      "epoch": 0.10217800484001076,
      "grad_norm": 1.597226619720459,
      "learning_rate": 5.1075268817204305e-06,
      "loss": 1.3171,
      "step": 190
    },
    {
      "epoch": 0.10755579456843238,
      "grad_norm": 1.652500867843628,
      "learning_rate": 5.376344086021505e-06,
      "loss": 1.3062,
      "step": 200
    },
    {
      "epoch": 0.11293358429685399,
      "grad_norm": 1.9103431701660156,
      "learning_rate": 5.64516129032258e-06,
      "loss": 1.3152,
      "step": 210
    },
    {
      "epoch": 0.11831137402527561,
      "grad_norm": 1.867384910583496,
      "learning_rate": 5.913978494623656e-06,
      "loss": 1.2755,
      "step": 220
    },
    {
      "epoch": 0.12368916375369723,
      "grad_norm": 1.948811411857605,
      "learning_rate": 6.182795698924731e-06,
      "loss": 1.2668,
      "step": 230
    },
    {
      "epoch": 0.12906695348211886,
      "grad_norm": 2.6351816654205322,
      "learning_rate": 6.451612903225806e-06,
      "loss": 1.2398,
      "step": 240
    },
    {
      "epoch": 0.13444474321054048,
      "grad_norm": 2.3845160007476807,
      "learning_rate": 6.720430107526882e-06,
      "loss": 1.2482,
      "step": 250
    },
    {
      "epoch": 0.13982253293896207,
      "grad_norm": 2.756230592727661,
      "learning_rate": 6.989247311827957e-06,
      "loss": 1.2344,
      "step": 260
    },
    {
      "epoch": 0.1452003226673837,
      "grad_norm": 4.0988922119140625,
      "learning_rate": 7.258064516129032e-06,
      "loss": 1.1628,
      "step": 270
    },
    {
      "epoch": 0.15057811239580532,
      "grad_norm": 3.285792350769043,
      "learning_rate": 7.526881720430107e-06,
      "loss": 1.1879,
      "step": 280
    },
    {
      "epoch": 0.15595590212422694,
      "grad_norm": 5.698833465576172,
      "learning_rate": 7.795698924731183e-06,
      "loss": 1.1777,
      "step": 290
    },
    {
      "epoch": 0.16133369185264856,
      "grad_norm": 3.003615379333496,
      "learning_rate": 8.064516129032258e-06,
      "loss": 1.0909,
      "step": 300
    },
    {
      "epoch": 0.1667114815810702,
      "grad_norm": 4.393281936645508,
      "learning_rate": 8.333333333333334e-06,
      "loss": 1.1232,
      "step": 310
    },
    {
      "epoch": 0.1720892713094918,
      "grad_norm": 3.947561502456665,
      "learning_rate": 8.602150537634409e-06,
      "loss": 1.1999,
      "step": 320
    },
    {
      "epoch": 0.1774670610379134,
      "grad_norm": 4.6220526695251465,
      "learning_rate": 8.870967741935484e-06,
      "loss": 1.203,
      "step": 330
    },
    {
      "epoch": 0.18284485076633503,
      "grad_norm": 5.380972862243652,
      "learning_rate": 9.13978494623656e-06,
      "loss": 1.1466,
      "step": 340
    },
    {
      "epoch": 0.18822264049475665,
      "grad_norm": 3.610668897628784,
      "learning_rate": 9.408602150537635e-06,
      "loss": 1.1706,
      "step": 350
    },
    {
      "epoch": 0.19360043022317827,
      "grad_norm": 4.87019157409668,
      "learning_rate": 9.67741935483871e-06,
      "loss": 1.0863,
      "step": 360
    },
    {
      "epoch": 0.1989782199515999,
      "grad_norm": 4.749124526977539,
      "learning_rate": 9.946236559139786e-06,
      "loss": 1.1215,
      "step": 370
    },
    {
      "epoch": 0.20435600968002152,
      "grad_norm": 3.9850399494171143,
      "learning_rate": 1.0215053763440861e-05,
      "loss": 1.1055,
      "step": 380
    },
    {
      "epoch": 0.20973379940844314,
      "grad_norm": 4.450169086456299,
      "learning_rate": 1.0483870967741936e-05,
      "loss": 1.1716,
      "step": 390
    },
    {
      "epoch": 0.21511158913686476,
      "grad_norm": 6.539676189422607,
      "learning_rate": 1.075268817204301e-05,
      "loss": 1.1364,
      "step": 400
    },
    {
      "epoch": 0.22048937886528636,
      "grad_norm": 3.689626932144165,
      "learning_rate": 1.1021505376344087e-05,
      "loss": 1.0723,
      "step": 410
    },
    {
      "epoch": 0.22586716859370798,
      "grad_norm": 4.124805450439453,
      "learning_rate": 1.129032258064516e-05,
      "loss": 1.155,
      "step": 420
    },
    {
      "epoch": 0.2312449583221296,
      "grad_norm": 3.5880370140075684,
      "learning_rate": 1.1559139784946236e-05,
      "loss": 1.0948,
      "step": 430
    },
    {
      "epoch": 0.23662274805055122,
      "grad_norm": 5.056119918823242,
      "learning_rate": 1.1827956989247311e-05,
      "loss": 1.0265,
      "step": 440
    },
    {
      "epoch": 0.24200053777897285,
      "grad_norm": 3.5723671913146973,
      "learning_rate": 1.2096774193548387e-05,
      "loss": 1.1157,
      "step": 450
    },
    {
      "epoch": 0.24737832750739447,
      "grad_norm": 4.087574005126953,
      "learning_rate": 1.2365591397849462e-05,
      "loss": 1.1463,
      "step": 460
    },
    {
      "epoch": 0.2527561172358161,
      "grad_norm": 4.360912799835205,
      "learning_rate": 1.2634408602150537e-05,
      "loss": 1.0837,
      "step": 470
    },
    {
      "epoch": 0.2581339069642377,
      "grad_norm": 4.904162883758545,
      "learning_rate": 1.2903225806451613e-05,
      "loss": 1.1275,
      "step": 480
    },
    {
      "epoch": 0.26351169669265934,
      "grad_norm": 6.1298089027404785,
      "learning_rate": 1.3172043010752688e-05,
      "loss": 1.1401,
      "step": 490
    },
    {
      "epoch": 0.26888948642108096,
      "grad_norm": 4.584622383117676,
      "learning_rate": 1.3440860215053763e-05,
      "loss": 1.1348,
      "step": 500
    },
    {
      "epoch": 0.2742672761495026,
      "grad_norm": 3.7440173625946045,
      "learning_rate": 1.3709677419354839e-05,
      "loss": 1.1111,
      "step": 510
    },
    {
      "epoch": 0.27964506587792415,
      "grad_norm": 2.9146933555603027,
      "learning_rate": 1.3978494623655914e-05,
      "loss": 1.0796,
      "step": 520
    },
    {
      "epoch": 0.28502285560634577,
      "grad_norm": 3.6589367389678955,
      "learning_rate": 1.424731182795699e-05,
      "loss": 1.0305,
      "step": 530
    },
    {
      "epoch": 0.2904006453347674,
      "grad_norm": 5.855048656463623,
      "learning_rate": 1.4516129032258065e-05,
      "loss": 1.0627,
      "step": 540
    },
    {
      "epoch": 0.295778435063189,
      "grad_norm": 4.392842769622803,
      "learning_rate": 1.478494623655914e-05,
      "loss": 1.1041,
      "step": 550
    },
    {
      "epoch": 0.30115622479161064,
      "grad_norm": 4.9848408699035645,
      "learning_rate": 1.5053763440860214e-05,
      "loss": 1.1148,
      "step": 560
    },
    {
      "epoch": 0.30653401452003226,
      "grad_norm": 4.155999183654785,
      "learning_rate": 1.532258064516129e-05,
      "loss": 1.0666,
      "step": 570
    },
    {
      "epoch": 0.3119118042484539,
      "grad_norm": 5.287778854370117,
      "learning_rate": 1.5591397849462366e-05,
      "loss": 1.0697,
      "step": 580
    },
    {
      "epoch": 0.3172895939768755,
      "grad_norm": 5.194242000579834,
      "learning_rate": 1.5860215053763443e-05,
      "loss": 1.1177,
      "step": 590
    },
    {
      "epoch": 0.32266738370529713,
      "grad_norm": 4.204605579376221,
      "learning_rate": 1.6129032258064517e-05,
      "loss": 1.0074,
      "step": 600
    },
    {
      "epoch": 0.32804517343371875,
      "grad_norm": 5.1562418937683105,
      "learning_rate": 1.639784946236559e-05,
      "loss": 1.0566,
      "step": 610
    },
    {
      "epoch": 0.3334229631621404,
      "grad_norm": 5.078306198120117,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 1.042,
      "step": 620
    },
    {
      "epoch": 0.338800752890562,
      "grad_norm": 3.163529872894287,
      "learning_rate": 1.6935483870967744e-05,
      "loss": 1.0587,
      "step": 630
    },
    {
      "epoch": 0.3441785426189836,
      "grad_norm": 4.752514839172363,
      "learning_rate": 1.7204301075268818e-05,
      "loss": 1.0226,
      "step": 640
    },
    {
      "epoch": 0.34955633234740524,
      "grad_norm": 3.928523302078247,
      "learning_rate": 1.7473118279569892e-05,
      "loss": 1.0451,
      "step": 650
    },
    {
      "epoch": 0.3549341220758268,
      "grad_norm": 4.8091959953308105,
      "learning_rate": 1.7715053763440862e-05,
      "loss": 1.02,
      "step": 660
    },
    {
      "epoch": 0.36031191180424843,
      "grad_norm": 6.587226867675781,
      "learning_rate": 1.7983870967741936e-05,
      "loss": 1.0455,
      "step": 670
    },
    {
      "epoch": 0.36568970153267005,
      "grad_norm": 3.9543919563293457,
      "learning_rate": 1.8252688172043013e-05,
      "loss": 1.0402,
      "step": 680
    },
    {
      "epoch": 0.3710674912610917,
      "grad_norm": 8.433939933776855,
      "learning_rate": 1.8521505376344086e-05,
      "loss": 0.9486,
      "step": 690
    },
    {
      "epoch": 0.3764452809895133,
      "grad_norm": 7.051844120025635,
      "learning_rate": 1.879032258064516e-05,
      "loss": 0.9602,
      "step": 700
    },
    {
      "epoch": 0.3818230707179349,
      "grad_norm": 4.706651210784912,
      "learning_rate": 1.9059139784946237e-05,
      "loss": 0.999,
      "step": 710
    },
    {
      "epoch": 0.38720086044635654,
      "grad_norm": 5.243274211883545,
      "learning_rate": 1.932795698924731e-05,
      "loss": 1.061,
      "step": 720
    },
    {
      "epoch": 0.39257865017477817,
      "grad_norm": 8.00699520111084,
      "learning_rate": 1.9596774193548388e-05,
      "loss": 1.0437,
      "step": 730
    },
    {
      "epoch": 0.3979564399031998,
      "grad_norm": 4.202841281890869,
      "learning_rate": 1.986559139784946e-05,
      "loss": 1.044,
      "step": 740
    },
    {
      "epoch": 0.4033342296316214,
      "grad_norm": 4.44482946395874,
      "learning_rate": 2.013440860215054e-05,
      "loss": 0.9578,
      "step": 750
    },
    {
      "epoch": 0.40871201936004303,
      "grad_norm": 4.5044169425964355,
      "learning_rate": 2.0403225806451612e-05,
      "loss": 1.0703,
      "step": 760
    },
    {
      "epoch": 0.41408980908846466,
      "grad_norm": 5.130634784698486,
      "learning_rate": 2.067204301075269e-05,
      "loss": 1.0554,
      "step": 770
    },
    {
      "epoch": 0.4194675988168863,
      "grad_norm": 4.708817005157471,
      "learning_rate": 2.0940860215053763e-05,
      "loss": 0.9745,
      "step": 780
    },
    {
      "epoch": 0.4248453885453079,
      "grad_norm": 5.373555660247803,
      "learning_rate": 2.120967741935484e-05,
      "loss": 1.0068,
      "step": 790
    },
    {
      "epoch": 0.4302231782737295,
      "grad_norm": 6.897604465484619,
      "learning_rate": 2.1478494623655913e-05,
      "loss": 1.0824,
      "step": 800
    },
    {
      "epoch": 0.4356009680021511,
      "grad_norm": 4.949418544769287,
      "learning_rate": 2.174731182795699e-05,
      "loss": 1.0263,
      "step": 810
    },
    {
      "epoch": 0.4409787577305727,
      "grad_norm": 5.5675950050354,
      "learning_rate": 2.2016129032258064e-05,
      "loss": 0.9298,
      "step": 820
    },
    {
      "epoch": 0.44635654745899433,
      "grad_norm": 4.999544143676758,
      "learning_rate": 2.228494623655914e-05,
      "loss": 1.0041,
      "step": 830
    },
    {
      "epoch": 0.45173433718741596,
      "grad_norm": 6.512686729431152,
      "learning_rate": 2.2553763440860215e-05,
      "loss": 0.9588,
      "step": 840
    },
    {
      "epoch": 0.4571121269158376,
      "grad_norm": 5.031947135925293,
      "learning_rate": 2.2822580645161292e-05,
      "loss": 1.0247,
      "step": 850
    },
    {
      "epoch": 0.4624899166442592,
      "grad_norm": 4.8657546043396,
      "learning_rate": 2.3091397849462365e-05,
      "loss": 0.9739,
      "step": 860
    },
    {
      "epoch": 0.4678677063726808,
      "grad_norm": 7.2087860107421875,
      "learning_rate": 2.3360215053763442e-05,
      "loss": 0.9595,
      "step": 870
    },
    {
      "epoch": 0.47324549610110245,
      "grad_norm": 5.248872756958008,
      "learning_rate": 2.3629032258064516e-05,
      "loss": 0.9941,
      "step": 880
    },
    {
      "epoch": 0.47862328582952407,
      "grad_norm": 9.160724639892578,
      "learning_rate": 2.3897849462365593e-05,
      "loss": 0.9508,
      "step": 890
    },
    {
      "epoch": 0.4840010755579457,
      "grad_norm": 7.173134803771973,
      "learning_rate": 2.4166666666666667e-05,
      "loss": 0.9335,
      "step": 900
    },
    {
      "epoch": 0.4893788652863673,
      "grad_norm": 5.578668117523193,
      "learning_rate": 2.4435483870967744e-05,
      "loss": 0.9705,
      "step": 910
    },
    {
      "epoch": 0.49475665501478894,
      "grad_norm": 6.3931403160095215,
      "learning_rate": 2.4704301075268817e-05,
      "loss": 0.899,
      "step": 920
    },
    {
      "epoch": 0.5001344447432106,
      "grad_norm": 4.444451808929443,
      "learning_rate": 2.4973118279569895e-05,
      "loss": 0.9959,
      "step": 930
    },
    {
      "epoch": 0.5055122344716322,
      "grad_norm": 5.209525108337402,
      "learning_rate": 2.5241935483870968e-05,
      "loss": 0.9308,
      "step": 940
    },
    {
      "epoch": 0.5108900242000538,
      "grad_norm": 7.359387397766113,
      "learning_rate": 2.5510752688172042e-05,
      "loss": 0.9033,
      "step": 950
    },
    {
      "epoch": 0.5162678139284754,
      "grad_norm": 5.6382551193237305,
      "learning_rate": 2.577956989247312e-05,
      "loss": 0.8913,
      "step": 960
    },
    {
      "epoch": 0.521645603656897,
      "grad_norm": 5.955422401428223,
      "learning_rate": 2.6048387096774196e-05,
      "loss": 0.9115,
      "step": 970
    },
    {
      "epoch": 0.5270233933853187,
      "grad_norm": 6.679576396942139,
      "learning_rate": 2.631720430107527e-05,
      "loss": 1.0033,
      "step": 980
    },
    {
      "epoch": 0.5324011831137403,
      "grad_norm": 4.3639984130859375,
      "learning_rate": 2.6586021505376343e-05,
      "loss": 1.0282,
      "step": 990
    },
    {
      "epoch": 0.5377789728421619,
      "grad_norm": 4.477341651916504,
      "learning_rate": 2.685483870967742e-05,
      "loss": 0.842,
      "step": 1000
    },
    {
      "epoch": 0.5431567625705835,
      "grad_norm": 5.171954154968262,
      "learning_rate": 2.7123655913978497e-05,
      "loss": 0.9248,
      "step": 1010
    },
    {
      "epoch": 0.5485345522990052,
      "grad_norm": 5.8592753410339355,
      "learning_rate": 2.739247311827957e-05,
      "loss": 0.934,
      "step": 1020
    },
    {
      "epoch": 0.5539123420274267,
      "grad_norm": 8.39183235168457,
      "learning_rate": 2.7661290322580644e-05,
      "loss": 1.0032,
      "step": 1030
    },
    {
      "epoch": 0.5592901317558483,
      "grad_norm": 5.890754222869873,
      "learning_rate": 2.793010752688172e-05,
      "loss": 0.9363,
      "step": 1040
    },
    {
      "epoch": 0.5646679214842699,
      "grad_norm": 5.755273818969727,
      "learning_rate": 2.81989247311828e-05,
      "loss": 0.944,
      "step": 1050
    },
    {
      "epoch": 0.5700457112126915,
      "grad_norm": 5.417993545532227,
      "learning_rate": 2.8467741935483872e-05,
      "loss": 0.9585,
      "step": 1060
    },
    {
      "epoch": 0.5754235009411132,
      "grad_norm": 5.7428178787231445,
      "learning_rate": 2.8736559139784946e-05,
      "loss": 0.9111,
      "step": 1070
    },
    {
      "epoch": 0.5808012906695348,
      "grad_norm": 5.430394649505615,
      "learning_rate": 2.9005376344086023e-05,
      "loss": 0.9968,
      "step": 1080
    },
    {
      "epoch": 0.5861790803979564,
      "grad_norm": 6.694816589355469,
      "learning_rate": 2.9274193548387097e-05,
      "loss": 1.0068,
      "step": 1090
    },
    {
      "epoch": 0.591556870126378,
      "grad_norm": 5.578295707702637,
      "learning_rate": 2.9543010752688174e-05,
      "loss": 0.9281,
      "step": 1100
    },
    {
      "epoch": 0.5969346598547997,
      "grad_norm": 5.788190841674805,
      "learning_rate": 2.9811827956989247e-05,
      "loss": 0.9164,
      "step": 1110
    },
    {
      "epoch": 0.6023124495832213,
      "grad_norm": 5.937402248382568,
      "learning_rate": 2.999103407053198e-05,
      "loss": 0.8553,
      "step": 1120
    },
    {
      "epoch": 0.6076902393116429,
      "grad_norm": 6.699580669403076,
      "learning_rate": 2.9961147638971906e-05,
      "loss": 0.9484,
      "step": 1130
    },
    {
      "epoch": 0.6130680290400645,
      "grad_norm": 9.155875205993652,
      "learning_rate": 2.9931261207411836e-05,
      "loss": 0.8545,
      "step": 1140
    },
    {
      "epoch": 0.6184458187684861,
      "grad_norm": 6.426059246063232,
      "learning_rate": 2.9901374775851765e-05,
      "loss": 0.8484,
      "step": 1150
    },
    {
      "epoch": 0.6238236084969078,
      "grad_norm": 7.7369537353515625,
      "learning_rate": 2.9871488344291694e-05,
      "loss": 0.8739,
      "step": 1160
    },
    {
      "epoch": 0.6292013982253294,
      "grad_norm": 7.3332061767578125,
      "learning_rate": 2.9841601912731623e-05,
      "loss": 0.8783,
      "step": 1170
    },
    {
      "epoch": 0.634579187953751,
      "grad_norm": 5.439231872558594,
      "learning_rate": 2.981171548117155e-05,
      "loss": 0.9417,
      "step": 1180
    },
    {
      "epoch": 0.6399569776821726,
      "grad_norm": 8.129547119140625,
      "learning_rate": 2.9781829049611478e-05,
      "loss": 0.9564,
      "step": 1190
    },
    {
      "epoch": 0.6453347674105943,
      "grad_norm": 5.4199137687683105,
      "learning_rate": 2.9751942618051404e-05,
      "loss": 0.9149,
      "step": 1200
    },
    {
      "epoch": 0.6507125571390159,
      "grad_norm": 4.559516429901123,
      "learning_rate": 2.9722056186491333e-05,
      "loss": 0.8639,
      "step": 1210
    },
    {
      "epoch": 0.6560903468674375,
      "grad_norm": 4.908379554748535,
      "learning_rate": 2.9692169754931262e-05,
      "loss": 0.9112,
      "step": 1220
    },
    {
      "epoch": 0.6614681365958591,
      "grad_norm": 4.902555465698242,
      "learning_rate": 2.9662283323371188e-05,
      "loss": 0.9422,
      "step": 1230
    },
    {
      "epoch": 0.6668459263242807,
      "grad_norm": 9.939236640930176,
      "learning_rate": 2.9632396891811117e-05,
      "loss": 0.7716,
      "step": 1240
    },
    {
      "epoch": 0.6722237160527024,
      "grad_norm": 9.43149185180664,
      "learning_rate": 2.9602510460251046e-05,
      "loss": 0.8242,
      "step": 1250
    },
    {
      "epoch": 0.677601505781124,
      "grad_norm": 5.832576274871826,
      "learning_rate": 2.9572624028690976e-05,
      "loss": 0.8942,
      "step": 1260
    },
    {
      "epoch": 0.6829792955095456,
      "grad_norm": 6.611307144165039,
      "learning_rate": 2.9542737597130905e-05,
      "loss": 0.8872,
      "step": 1270
    },
    {
      "epoch": 0.6883570852379672,
      "grad_norm": 6.069116115570068,
      "learning_rate": 2.951285116557083e-05,
      "loss": 0.8429,
      "step": 1280
    },
    {
      "epoch": 0.6937348749663889,
      "grad_norm": 5.546591758728027,
      "learning_rate": 2.948296473401076e-05,
      "loss": 0.8484,
      "step": 1290
    },
    {
      "epoch": 0.6991126646948105,
      "grad_norm": 7.142210483551025,
      "learning_rate": 2.945307830245069e-05,
      "loss": 0.9201,
      "step": 1300
    },
    {
      "epoch": 0.7044904544232321,
      "grad_norm": 6.044034957885742,
      "learning_rate": 2.9423191870890618e-05,
      "loss": 0.9421,
      "step": 1310
    },
    {
      "epoch": 0.7098682441516536,
      "grad_norm": 6.765344619750977,
      "learning_rate": 2.9393305439330547e-05,
      "loss": 0.8657,
      "step": 1320
    },
    {
      "epoch": 0.7152460338800752,
      "grad_norm": 8.543851852416992,
      "learning_rate": 2.9363419007770473e-05,
      "loss": 0.8995,
      "step": 1330
    },
    {
      "epoch": 0.7206238236084969,
      "grad_norm": 6.265585422515869,
      "learning_rate": 2.93335325762104e-05,
      "loss": 0.8771,
      "step": 1340
    },
    {
      "epoch": 0.7260016133369185,
      "grad_norm": 7.85948371887207,
      "learning_rate": 2.9303646144650328e-05,
      "loss": 0.9209,
      "step": 1350
    },
    {
      "epoch": 0.7313794030653401,
      "grad_norm": 6.425928592681885,
      "learning_rate": 2.9273759713090257e-05,
      "loss": 0.844,
      "step": 1360
    },
    {
      "epoch": 0.7367571927937617,
      "grad_norm": 10.369342803955078,
      "learning_rate": 2.9243873281530186e-05,
      "loss": 1.0116,
      "step": 1370
    },
    {
      "epoch": 0.7421349825221834,
      "grad_norm": 4.890946388244629,
      "learning_rate": 2.9213986849970116e-05,
      "loss": 0.8212,
      "step": 1380
    },
    {
      "epoch": 0.747512772250605,
      "grad_norm": 8.27615737915039,
      "learning_rate": 2.918410041841004e-05,
      "loss": 0.8041,
      "step": 1390
    },
    {
      "epoch": 0.7528905619790266,
      "grad_norm": 7.467518329620361,
      "learning_rate": 2.915421398684997e-05,
      "loss": 0.9183,
      "step": 1400
    },
    {
      "epoch": 0.7582683517074482,
      "grad_norm": 7.204281330108643,
      "learning_rate": 2.91243275552899e-05,
      "loss": 0.8648,
      "step": 1410
    },
    {
      "epoch": 0.7636461414358698,
      "grad_norm": 6.196351051330566,
      "learning_rate": 2.909444112372983e-05,
      "loss": 0.8218,
      "step": 1420
    },
    {
      "epoch": 0.7690239311642915,
      "grad_norm": 7.91864538192749,
      "learning_rate": 2.9064554692169758e-05,
      "loss": 0.7793,
      "step": 1430
    },
    {
      "epoch": 0.7744017208927131,
      "grad_norm": 9.066834449768066,
      "learning_rate": 2.9034668260609684e-05,
      "loss": 0.8485,
      "step": 1440
    },
    {
      "epoch": 0.7797795106211347,
      "grad_norm": 5.281524181365967,
      "learning_rate": 2.9004781829049613e-05,
      "loss": 0.8757,
      "step": 1450
    },
    {
      "epoch": 0.7851573003495563,
      "grad_norm": 6.360345840454102,
      "learning_rate": 2.897489539748954e-05,
      "loss": 0.8889,
      "step": 1460
    },
    {
      "epoch": 0.790535090077978,
      "grad_norm": 7.0374603271484375,
      "learning_rate": 2.8945008965929468e-05,
      "loss": 0.7303,
      "step": 1470
    },
    {
      "epoch": 0.7959128798063996,
      "grad_norm": 8.377225875854492,
      "learning_rate": 2.8915122534369397e-05,
      "loss": 0.8745,
      "step": 1480
    },
    {
      "epoch": 0.8012906695348212,
      "grad_norm": 7.462434768676758,
      "learning_rate": 2.8885236102809323e-05,
      "loss": 0.7555,
      "step": 1490
    },
    {
      "epoch": 0.8066684592632428,
      "grad_norm": 6.211448669433594,
      "learning_rate": 2.8855349671249252e-05,
      "loss": 0.8244,
      "step": 1500
    },
    {
      "epoch": 0.8120462489916644,
      "grad_norm": 7.2000627517700195,
      "learning_rate": 2.882546323968918e-05,
      "loss": 0.8111,
      "step": 1510
    },
    {
      "epoch": 0.8174240387200861,
      "grad_norm": 7.9124627113342285,
      "learning_rate": 2.879557680812911e-05,
      "loss": 0.7819,
      "step": 1520
    },
    {
      "epoch": 0.8228018284485077,
      "grad_norm": 6.205093860626221,
      "learning_rate": 2.876569037656904e-05,
      "loss": 0.7477,
      "step": 1530
    },
    {
      "epoch": 0.8281796181769293,
      "grad_norm": 5.14741849899292,
      "learning_rate": 2.873580394500897e-05,
      "loss": 0.7847,
      "step": 1540
    },
    {
      "epoch": 0.8335574079053509,
      "grad_norm": 8.981539726257324,
      "learning_rate": 2.8705917513448895e-05,
      "loss": 0.7636,
      "step": 1550
    },
    {
      "epoch": 0.8389351976337726,
      "grad_norm": 7.385237693786621,
      "learning_rate": 2.8676031081888824e-05,
      "loss": 0.7552,
      "step": 1560
    },
    {
      "epoch": 0.8443129873621942,
      "grad_norm": 6.372334957122803,
      "learning_rate": 2.8646144650328753e-05,
      "loss": 0.7343,
      "step": 1570
    },
    {
      "epoch": 0.8496907770906158,
      "grad_norm": 6.192144870758057,
      "learning_rate": 2.8616258218768682e-05,
      "loss": 0.7889,
      "step": 1580
    },
    {
      "epoch": 0.8550685668190374,
      "grad_norm": 10.118911743164062,
      "learning_rate": 2.8586371787208608e-05,
      "loss": 0.7336,
      "step": 1590
    },
    {
      "epoch": 0.860446356547459,
      "grad_norm": 7.890825271606445,
      "learning_rate": 2.8556485355648534e-05,
      "loss": 0.873,
      "step": 1600
    },
    {
      "epoch": 0.8658241462758807,
      "grad_norm": 7.989941596984863,
      "learning_rate": 2.8526598924088463e-05,
      "loss": 0.8617,
      "step": 1610
    },
    {
      "epoch": 0.8712019360043022,
      "grad_norm": 9.096136093139648,
      "learning_rate": 2.8496712492528392e-05,
      "loss": 0.7883,
      "step": 1620
    },
    {
      "epoch": 0.8765797257327238,
      "grad_norm": 7.109315872192383,
      "learning_rate": 2.846682606096832e-05,
      "loss": 0.7753,
      "step": 1630
    },
    {
      "epoch": 0.8819575154611454,
      "grad_norm": 8.226037979125977,
      "learning_rate": 2.843693962940825e-05,
      "loss": 0.777,
      "step": 1640
    },
    {
      "epoch": 0.887335305189567,
      "grad_norm": 5.3698015213012695,
      "learning_rate": 2.8407053197848176e-05,
      "loss": 0.8012,
      "step": 1650
    },
    {
      "epoch": 0.8927130949179887,
      "grad_norm": 6.800804138183594,
      "learning_rate": 2.8377166766288105e-05,
      "loss": 0.7141,
      "step": 1660
    },
    {
      "epoch": 0.8980908846464103,
      "grad_norm": 10.038408279418945,
      "learning_rate": 2.8347280334728035e-05,
      "loss": 0.7855,
      "step": 1670
    },
    {
      "epoch": 0.9034686743748319,
      "grad_norm": 8.214665412902832,
      "learning_rate": 2.8317393903167964e-05,
      "loss": 0.7825,
      "step": 1680
    },
    {
      "epoch": 0.9088464641032535,
      "grad_norm": 9.448484420776367,
      "learning_rate": 2.8287507471607893e-05,
      "loss": 0.7946,
      "step": 1690
    },
    {
      "epoch": 0.9142242538316752,
      "grad_norm": 6.858295917510986,
      "learning_rate": 2.825762104004782e-05,
      "loss": 0.8055,
      "step": 1700
    },
    {
      "epoch": 0.9196020435600968,
      "grad_norm": 8.383428573608398,
      "learning_rate": 2.8227734608487748e-05,
      "loss": 0.7713,
      "step": 1710
    },
    {
      "epoch": 0.9249798332885184,
      "grad_norm": 8.19688606262207,
      "learning_rate": 2.8197848176927674e-05,
      "loss": 0.8625,
      "step": 1720
    },
    {
      "epoch": 0.93035762301694,
      "grad_norm": 5.957319259643555,
      "learning_rate": 2.8167961745367603e-05,
      "loss": 0.7666,
      "step": 1730
    },
    {
      "epoch": 0.9357354127453616,
      "grad_norm": 6.98301887512207,
      "learning_rate": 2.8138075313807532e-05,
      "loss": 0.8038,
      "step": 1740
    },
    {
      "epoch": 0.9411132024737833,
      "grad_norm": 6.267243385314941,
      "learning_rate": 2.810818888224746e-05,
      "loss": 0.7597,
      "step": 1750
    },
    {
      "epoch": 0.9464909922022049,
      "grad_norm": 8.77137565612793,
      "learning_rate": 2.8078302450687387e-05,
      "loss": 0.7987,
      "step": 1760
    },
    {
      "epoch": 0.9518687819306265,
      "grad_norm": 7.840683460235596,
      "learning_rate": 2.8048416019127316e-05,
      "loss": 0.826,
      "step": 1770
    },
    {
      "epoch": 0.9572465716590481,
      "grad_norm": 11.177462577819824,
      "learning_rate": 2.8018529587567245e-05,
      "loss": 0.742,
      "step": 1780
    },
    {
      "epoch": 0.9626243613874698,
      "grad_norm": 6.960690021514893,
      "learning_rate": 2.7988643156007175e-05,
      "loss": 0.7213,
      "step": 1790
    },
    {
      "epoch": 0.9680021511158914,
      "grad_norm": 9.867390632629395,
      "learning_rate": 2.7958756724447104e-05,
      "loss": 0.8872,
      "step": 1800
    },
    {
      "epoch": 0.973379940844313,
      "grad_norm": 7.225764274597168,
      "learning_rate": 2.792887029288703e-05,
      "loss": 0.765,
      "step": 1810
    },
    {
      "epoch": 0.9787577305727346,
      "grad_norm": 7.472442150115967,
      "learning_rate": 2.789898386132696e-05,
      "loss": 0.6943,
      "step": 1820
    },
    {
      "epoch": 0.9841355203011563,
      "grad_norm": 7.173036098480225,
      "learning_rate": 2.7869097429766888e-05,
      "loss": 0.819,
      "step": 1830
    },
    {
      "epoch": 0.9895133100295779,
      "grad_norm": 5.793645858764648,
      "learning_rate": 2.7839210998206817e-05,
      "loss": 0.7628,
      "step": 1840
    },
    {
      "epoch": 0.9948910997579995,
      "grad_norm": 7.453874111175537,
      "learning_rate": 2.7809324566646743e-05,
      "loss": 0.7729,
      "step": 1850
    },
    {
      "epoch": 1.0,
      "grad_norm": 6.157423496246338,
      "learning_rate": 2.777943813508667e-05,
      "loss": 0.6554,
      "step": 1860
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.7290574156245798,
      "eval_f1": 0.7193429854431402,
      "eval_loss": 0.7072713971138,
      "eval_runtime": 12.9898,
      "eval_samples_per_second": 1145.056,
      "eval_steps_per_second": 35.797,
      "step": 1860
    },
    {
      "epoch": 1.0053777897284215,
      "grad_norm": 6.134067535400391,
      "learning_rate": 2.7749551703526598e-05,
      "loss": 0.655,
      "step": 1870
    },
    {
      "epoch": 1.0107555794568432,
      "grad_norm": 7.382625579833984,
      "learning_rate": 2.7719665271966527e-05,
      "loss": 0.6087,
      "step": 1880
    },
    {
      "epoch": 1.0161333691852648,
      "grad_norm": 6.224303722381592,
      "learning_rate": 2.7689778840406456e-05,
      "loss": 0.591,
      "step": 1890
    },
    {
      "epoch": 1.0215111589136865,
      "grad_norm": 7.761265754699707,
      "learning_rate": 2.7659892408846385e-05,
      "loss": 0.6503,
      "step": 1900
    },
    {
      "epoch": 1.026888948642108,
      "grad_norm": 8.632120132446289,
      "learning_rate": 2.763000597728631e-05,
      "loss": 0.5998,
      "step": 1910
    },
    {
      "epoch": 1.0322667383705297,
      "grad_norm": 8.751175880432129,
      "learning_rate": 2.760011954572624e-05,
      "loss": 0.6332,
      "step": 1920
    },
    {
      "epoch": 1.0376445280989512,
      "grad_norm": 6.4937944412231445,
      "learning_rate": 2.757023311416617e-05,
      "loss": 0.6241,
      "step": 1930
    },
    {
      "epoch": 1.043022317827373,
      "grad_norm": 10.731334686279297,
      "learning_rate": 2.75403466826061e-05,
      "loss": 0.6521,
      "step": 1940
    },
    {
      "epoch": 1.0484001075557945,
      "grad_norm": 6.514125823974609,
      "learning_rate": 2.7510460251046028e-05,
      "loss": 0.5814,
      "step": 1950
    },
    {
      "epoch": 1.0537778972842162,
      "grad_norm": 9.78315258026123,
      "learning_rate": 2.7480573819485957e-05,
      "loss": 0.5779,
      "step": 1960
    },
    {
      "epoch": 1.0591556870126377,
      "grad_norm": 9.665119171142578,
      "learning_rate": 2.7450687387925883e-05,
      "loss": 0.5841,
      "step": 1970
    },
    {
      "epoch": 1.0645334767410595,
      "grad_norm": 6.368106842041016,
      "learning_rate": 2.742080095636581e-05,
      "loss": 0.5964,
      "step": 1980
    },
    {
      "epoch": 1.069911266469481,
      "grad_norm": 8.9453125,
      "learning_rate": 2.7390914524805738e-05,
      "loss": 0.4813,
      "step": 1990
    },
    {
      "epoch": 1.0752890561979027,
      "grad_norm": 6.371434688568115,
      "learning_rate": 2.7361028093245667e-05,
      "loss": 0.5624,
      "step": 2000
    },
    {
      "epoch": 1.0806668459263242,
      "grad_norm": 7.52341365814209,
      "learning_rate": 2.7331141661685596e-05,
      "loss": 0.5292,
      "step": 2010
    },
    {
      "epoch": 1.086044635654746,
      "grad_norm": 10.711287498474121,
      "learning_rate": 2.7301255230125522e-05,
      "loss": 0.5531,
      "step": 2020
    },
    {
      "epoch": 1.0914224253831675,
      "grad_norm": 9.081665992736816,
      "learning_rate": 2.727136879856545e-05,
      "loss": 0.5758,
      "step": 2030
    },
    {
      "epoch": 1.0968002151115892,
      "grad_norm": 6.702380180358887,
      "learning_rate": 2.724148236700538e-05,
      "loss": 0.6017,
      "step": 2040
    },
    {
      "epoch": 1.1021780048400107,
      "grad_norm": 7.166346549987793,
      "learning_rate": 2.721159593544531e-05,
      "loss": 0.6527,
      "step": 2050
    },
    {
      "epoch": 1.1075557945684325,
      "grad_norm": 6.739124298095703,
      "learning_rate": 2.718170950388524e-05,
      "loss": 0.5952,
      "step": 2060
    },
    {
      "epoch": 1.112933584296854,
      "grad_norm": 10.259089469909668,
      "learning_rate": 2.7151823072325165e-05,
      "loss": 0.5641,
      "step": 2070
    },
    {
      "epoch": 1.1183113740252757,
      "grad_norm": 15.03210163116455,
      "learning_rate": 2.7121936640765094e-05,
      "loss": 0.6528,
      "step": 2080
    },
    {
      "epoch": 1.1236891637536972,
      "grad_norm": 8.278463363647461,
      "learning_rate": 2.7092050209205023e-05,
      "loss": 0.5796,
      "step": 2090
    },
    {
      "epoch": 1.129066953482119,
      "grad_norm": 10.155570983886719,
      "learning_rate": 2.706216377764495e-05,
      "loss": 0.6411,
      "step": 2100
    },
    {
      "epoch": 1.1344447432105405,
      "grad_norm": 9.95628547668457,
      "learning_rate": 2.7032277346084878e-05,
      "loss": 0.5449,
      "step": 2110
    },
    {
      "epoch": 1.139822532938962,
      "grad_norm": 9.484634399414062,
      "learning_rate": 2.7002390914524804e-05,
      "loss": 0.5035,
      "step": 2120
    },
    {
      "epoch": 1.1452003226673837,
      "grad_norm": 5.51576042175293,
      "learning_rate": 2.6972504482964733e-05,
      "loss": 0.5324,
      "step": 2130
    },
    {
      "epoch": 1.1505781123958054,
      "grad_norm": 7.393925189971924,
      "learning_rate": 2.6942618051404662e-05,
      "loss": 0.6007,
      "step": 2140
    },
    {
      "epoch": 1.155955902124227,
      "grad_norm": 7.143028736114502,
      "learning_rate": 2.691273161984459e-05,
      "loss": 0.4996,
      "step": 2150
    },
    {
      "epoch": 1.1613336918526485,
      "grad_norm": 7.465884685516357,
      "learning_rate": 2.688284518828452e-05,
      "loss": 0.6406,
      "step": 2160
    },
    {
      "epoch": 1.1667114815810702,
      "grad_norm": 8.217516899108887,
      "learning_rate": 2.685295875672445e-05,
      "loss": 0.5259,
      "step": 2170
    },
    {
      "epoch": 1.172089271309492,
      "grad_norm": 8.01699447631836,
      "learning_rate": 2.6823072325164375e-05,
      "loss": 0.5083,
      "step": 2180
    },
    {
      "epoch": 1.1774670610379134,
      "grad_norm": 10.50483226776123,
      "learning_rate": 2.6793185893604305e-05,
      "loss": 0.6333,
      "step": 2190
    },
    {
      "epoch": 1.182844850766335,
      "grad_norm": 8.517562866210938,
      "learning_rate": 2.6763299462044234e-05,
      "loss": 0.5408,
      "step": 2200
    },
    {
      "epoch": 1.1882226404947567,
      "grad_norm": 5.989758491516113,
      "learning_rate": 2.6733413030484163e-05,
      "loss": 0.5155,
      "step": 2210
    },
    {
      "epoch": 1.1936004302231782,
      "grad_norm": 10.968958854675293,
      "learning_rate": 2.6703526598924092e-05,
      "loss": 0.5938,
      "step": 2220
    },
    {
      "epoch": 1.1989782199516,
      "grad_norm": 9.205936431884766,
      "learning_rate": 2.6673640167364018e-05,
      "loss": 0.6171,
      "step": 2230
    },
    {
      "epoch": 1.2043560096800214,
      "grad_norm": 11.549906730651855,
      "learning_rate": 2.6643753735803944e-05,
      "loss": 0.5359,
      "step": 2240
    },
    {
      "epoch": 1.2097337994084432,
      "grad_norm": 7.772980690002441,
      "learning_rate": 2.6613867304243873e-05,
      "loss": 0.5196,
      "step": 2250
    },
    {
      "epoch": 1.2151115891368647,
      "grad_norm": 5.878495693206787,
      "learning_rate": 2.6583980872683802e-05,
      "loss": 0.5446,
      "step": 2260
    },
    {
      "epoch": 1.2204893788652864,
      "grad_norm": 9.767724990844727,
      "learning_rate": 2.655409444112373e-05,
      "loss": 0.5695,
      "step": 2270
    },
    {
      "epoch": 1.225867168593708,
      "grad_norm": 6.378687381744385,
      "learning_rate": 2.6524208009563657e-05,
      "loss": 0.5448,
      "step": 2280
    },
    {
      "epoch": 1.2312449583221297,
      "grad_norm": 12.800618171691895,
      "learning_rate": 2.6494321578003586e-05,
      "loss": 0.5115,
      "step": 2290
    },
    {
      "epoch": 1.2366227480505512,
      "grad_norm": 9.885577201843262,
      "learning_rate": 2.6464435146443515e-05,
      "loss": 0.4737,
      "step": 2300
    },
    {
      "epoch": 1.242000537778973,
      "grad_norm": 9.916007041931152,
      "learning_rate": 2.6434548714883445e-05,
      "loss": 0.5613,
      "step": 2310
    },
    {
      "epoch": 1.2473783275073944,
      "grad_norm": 9.742633819580078,
      "learning_rate": 2.6404662283323374e-05,
      "loss": 0.5337,
      "step": 2320
    },
    {
      "epoch": 1.2527561172358161,
      "grad_norm": 4.9965434074401855,
      "learning_rate": 2.63747758517633e-05,
      "loss": 0.546,
      "step": 2330
    },
    {
      "epoch": 1.2581339069642377,
      "grad_norm": 12.800713539123535,
      "learning_rate": 2.634488942020323e-05,
      "loss": 0.5673,
      "step": 2340
    },
    {
      "epoch": 1.2635116966926594,
      "grad_norm": 11.110854148864746,
      "learning_rate": 2.6315002988643158e-05,
      "loss": 0.5494,
      "step": 2350
    },
    {
      "epoch": 1.268889486421081,
      "grad_norm": 8.61194133758545,
      "learning_rate": 2.6285116557083084e-05,
      "loss": 0.6225,
      "step": 2360
    },
    {
      "epoch": 1.2742672761495026,
      "grad_norm": 8.045934677124023,
      "learning_rate": 2.6255230125523013e-05,
      "loss": 0.5293,
      "step": 2370
    },
    {
      "epoch": 1.2796450658779241,
      "grad_norm": 6.896798610687256,
      "learning_rate": 2.622534369396294e-05,
      "loss": 0.5113,
      "step": 2380
    },
    {
      "epoch": 1.2850228556063459,
      "grad_norm": 7.412999153137207,
      "learning_rate": 2.6195457262402868e-05,
      "loss": 0.4663,
      "step": 2390
    },
    {
      "epoch": 1.2904006453347674,
      "grad_norm": 8.425886154174805,
      "learning_rate": 2.6165570830842797e-05,
      "loss": 0.6016,
      "step": 2400
    },
    {
      "epoch": 1.295778435063189,
      "grad_norm": 5.339468479156494,
      "learning_rate": 2.6135684399282726e-05,
      "loss": 0.5197,
      "step": 2410
    },
    {
      "epoch": 1.3011562247916106,
      "grad_norm": 7.721283912658691,
      "learning_rate": 2.6105797967722655e-05,
      "loss": 0.5364,
      "step": 2420
    },
    {
      "epoch": 1.3065340145200324,
      "grad_norm": 7.4944963455200195,
      "learning_rate": 2.6075911536162585e-05,
      "loss": 0.5425,
      "step": 2430
    },
    {
      "epoch": 1.3119118042484539,
      "grad_norm": 10.2117338180542,
      "learning_rate": 2.604602510460251e-05,
      "loss": 0.5328,
      "step": 2440
    },
    {
      "epoch": 1.3172895939768754,
      "grad_norm": 9.147470474243164,
      "learning_rate": 2.601613867304244e-05,
      "loss": 0.543,
      "step": 2450
    },
    {
      "epoch": 1.3226673837052971,
      "grad_norm": 9.546911239624023,
      "learning_rate": 2.598625224148237e-05,
      "loss": 0.4735,
      "step": 2460
    },
    {
      "epoch": 1.3280451734337189,
      "grad_norm": 10.793703079223633,
      "learning_rate": 2.5956365809922298e-05,
      "loss": 0.4973,
      "step": 2470
    },
    {
      "epoch": 1.3334229631621404,
      "grad_norm": 8.536364555358887,
      "learning_rate": 2.5926479378362227e-05,
      "loss": 0.5171,
      "step": 2480
    },
    {
      "epoch": 1.3388007528905619,
      "grad_norm": 8.39480972290039,
      "learning_rate": 2.589659294680215e-05,
      "loss": 0.5053,
      "step": 2490
    },
    {
      "epoch": 1.3441785426189836,
      "grad_norm": 6.68284797668457,
      "learning_rate": 2.586670651524208e-05,
      "loss": 0.4492,
      "step": 2500
    },
    {
      "epoch": 1.3495563323474054,
      "grad_norm": 4.834831714630127,
      "learning_rate": 2.5836820083682008e-05,
      "loss": 0.3821,
      "step": 2510
    },
    {
      "epoch": 1.3549341220758269,
      "grad_norm": 10.280723571777344,
      "learning_rate": 2.5806933652121937e-05,
      "loss": 0.5041,
      "step": 2520
    },
    {
      "epoch": 1.3603119118042484,
      "grad_norm": Infinity,
      "learning_rate": 2.578003586371787e-05,
      "loss": 0.5926,
      "step": 2530
    },
    {
      "epoch": 1.36568970153267,
      "grad_norm": 8.032023429870605,
      "learning_rate": 2.57501494321578e-05,
      "loss": 0.4973,
      "step": 2540
    },
    {
      "epoch": 1.3710674912610916,
      "grad_norm": 11.102745056152344,
      "learning_rate": 2.5720263000597728e-05,
      "loss": 0.4936,
      "step": 2550
    },
    {
      "epoch": 1.3764452809895134,
      "grad_norm": 6.3695855140686035,
      "learning_rate": 2.5690376569037657e-05,
      "loss": 0.4526,
      "step": 2560
    },
    {
      "epoch": 1.3818230707179349,
      "grad_norm": 7.229729652404785,
      "learning_rate": 2.5660490137477586e-05,
      "loss": 0.4751,
      "step": 2570
    },
    {
      "epoch": 1.3872008604463566,
      "grad_norm": 9.69044303894043,
      "learning_rate": 2.5630603705917512e-05,
      "loss": 0.4626,
      "step": 2580
    },
    {
      "epoch": 1.392578650174778,
      "grad_norm": 11.945899963378906,
      "learning_rate": 2.560071727435744e-05,
      "loss": 0.4862,
      "step": 2590
    },
    {
      "epoch": 1.3979564399031998,
      "grad_norm": 12.45004653930664,
      "learning_rate": 2.557083084279737e-05,
      "loss": 0.5331,
      "step": 2600
    },
    {
      "epoch": 1.4033342296316214,
      "grad_norm": 9.700933456420898,
      "learning_rate": 2.55409444112373e-05,
      "loss": 0.4966,
      "step": 2610
    },
    {
      "epoch": 1.408712019360043,
      "grad_norm": 8.509307861328125,
      "learning_rate": 2.551105797967723e-05,
      "loss": 0.4718,
      "step": 2620
    },
    {
      "epoch": 1.4140898090884646,
      "grad_norm": 11.821306228637695,
      "learning_rate": 2.5481171548117158e-05,
      "loss": 0.4449,
      "step": 2630
    },
    {
      "epoch": 1.4194675988168863,
      "grad_norm": 5.687198638916016,
      "learning_rate": 2.5451285116557084e-05,
      "loss": 0.4956,
      "step": 2640
    },
    {
      "epoch": 1.4248453885453078,
      "grad_norm": 9.59984302520752,
      "learning_rate": 2.5421398684997013e-05,
      "loss": 0.4604,
      "step": 2650
    },
    {
      "epoch": 1.4302231782737296,
      "grad_norm": 11.63711929321289,
      "learning_rate": 2.539151225343694e-05,
      "loss": 0.5068,
      "step": 2660
    },
    {
      "epoch": 1.435600968002151,
      "grad_norm": 9.992781639099121,
      "learning_rate": 2.5361625821876868e-05,
      "loss": 0.4822,
      "step": 2670
    },
    {
      "epoch": 1.4409787577305728,
      "grad_norm": 6.661069869995117,
      "learning_rate": 2.5331739390316797e-05,
      "loss": 0.508,
      "step": 2680
    },
    {
      "epoch": 1.4463565474589943,
      "grad_norm": 10.593815803527832,
      "learning_rate": 2.5301852958756723e-05,
      "loss": 0.4576,
      "step": 2690
    },
    {
      "epoch": 1.4517343371874158,
      "grad_norm": 17.02916717529297,
      "learning_rate": 2.5271966527196652e-05,
      "loss": 0.6377,
      "step": 2700
    },
    {
      "epoch": 1.4571121269158376,
      "grad_norm": 10.808152198791504,
      "learning_rate": 2.524208009563658e-05,
      "loss": 0.4312,
      "step": 2710
    },
    {
      "epoch": 1.4624899166442593,
      "grad_norm": 6.55012845993042,
      "learning_rate": 2.521219366407651e-05,
      "loss": 0.4684,
      "step": 2720
    },
    {
      "epoch": 1.4678677063726808,
      "grad_norm": 7.963891506195068,
      "learning_rate": 2.518230723251644e-05,
      "loss": 0.4794,
      "step": 2730
    },
    {
      "epoch": 1.4732454961011023,
      "grad_norm": 7.566233158111572,
      "learning_rate": 2.5152420800956365e-05,
      "loss": 0.4981,
      "step": 2740
    },
    {
      "epoch": 1.478623285829524,
      "grad_norm": 7.206212043762207,
      "learning_rate": 2.5122534369396295e-05,
      "loss": 0.5224,
      "step": 2750
    },
    {
      "epoch": 1.4840010755579458,
      "grad_norm": 7.992182731628418,
      "learning_rate": 2.5092647937836224e-05,
      "loss": 0.4247,
      "step": 2760
    },
    {
      "epoch": 1.4893788652863673,
      "grad_norm": 10.873143196105957,
      "learning_rate": 2.5062761506276153e-05,
      "loss": 0.4249,
      "step": 2770
    },
    {
      "epoch": 1.4947566550147888,
      "grad_norm": 10.651893615722656,
      "learning_rate": 2.5032875074716082e-05,
      "loss": 0.5005,
      "step": 2780
    },
    {
      "epoch": 1.5001344447432106,
      "grad_norm": 13.814923286437988,
      "learning_rate": 2.5002988643156005e-05,
      "loss": 0.5059,
      "step": 2790
    },
    {
      "epoch": 1.5055122344716323,
      "grad_norm": 9.960927963256836,
      "learning_rate": 2.4973102211595934e-05,
      "loss": 0.4524,
      "step": 2800
    },
    {
      "epoch": 1.5108900242000538,
      "grad_norm": 10.11943531036377,
      "learning_rate": 2.4943215780035863e-05,
      "loss": 0.5808,
      "step": 2810
    },
    {
      "epoch": 1.5162678139284753,
      "grad_norm": 11.440069198608398,
      "learning_rate": 2.4913329348475792e-05,
      "loss": 0.5402,
      "step": 2820
    },
    {
      "epoch": 1.521645603656897,
      "grad_norm": 12.116966247558594,
      "learning_rate": 2.488344291691572e-05,
      "loss": 0.5201,
      "step": 2830
    },
    {
      "epoch": 1.5270233933853188,
      "grad_norm": 12.030548095703125,
      "learning_rate": 2.485355648535565e-05,
      "loss": 0.471,
      "step": 2840
    },
    {
      "epoch": 1.5324011831137403,
      "grad_norm": 3.226119041442871,
      "learning_rate": 2.4823670053795576e-05,
      "loss": 0.4293,
      "step": 2850
    },
    {
      "epoch": 1.5377789728421618,
      "grad_norm": 11.324697494506836,
      "learning_rate": 2.4793783622235505e-05,
      "loss": 0.4999,
      "step": 2860
    },
    {
      "epoch": 1.5431567625705835,
      "grad_norm": 10.013729095458984,
      "learning_rate": 2.4763897190675435e-05,
      "loss": 0.4381,
      "step": 2870
    },
    {
      "epoch": 1.5485345522990053,
      "grad_norm": 11.574971199035645,
      "learning_rate": 2.4734010759115364e-05,
      "loss": 0.4994,
      "step": 2880
    },
    {
      "epoch": 1.5539123420274268,
      "grad_norm": 8.425446510314941,
      "learning_rate": 2.4704124327555293e-05,
      "loss": 0.457,
      "step": 2890
    },
    {
      "epoch": 1.5592901317558483,
      "grad_norm": 9.050065040588379,
      "learning_rate": 2.467423789599522e-05,
      "loss": 0.4788,
      "step": 2900
    },
    {
      "epoch": 1.5646679214842698,
      "grad_norm": 8.605626106262207,
      "learning_rate": 2.4644351464435148e-05,
      "loss": 0.4838,
      "step": 2910
    },
    {
      "epoch": 1.5700457112126915,
      "grad_norm": 6.936400413513184,
      "learning_rate": 2.4614465032875074e-05,
      "loss": 0.4951,
      "step": 2920
    },
    {
      "epoch": 1.5754235009411133,
      "grad_norm": 13.788171768188477,
      "learning_rate": 2.4584578601315003e-05,
      "loss": 0.5538,
      "step": 2930
    },
    {
      "epoch": 1.5808012906695348,
      "grad_norm": 9.496525764465332,
      "learning_rate": 2.4554692169754932e-05,
      "loss": 0.4799,
      "step": 2940
    },
    {
      "epoch": 1.5861790803979563,
      "grad_norm": 8.291266441345215,
      "learning_rate": 2.4524805738194858e-05,
      "loss": 0.4161,
      "step": 2950
    },
    {
      "epoch": 1.591556870126378,
      "grad_norm": 7.13575553894043,
      "learning_rate": 2.4494919306634787e-05,
      "loss": 0.4551,
      "step": 2960
    },
    {
      "epoch": 1.5969346598547998,
      "grad_norm": 7.991887092590332,
      "learning_rate": 2.4465032875074716e-05,
      "loss": 0.4575,
      "step": 2970
    },
    {
      "epoch": 1.6023124495832213,
      "grad_norm": 7.927361488342285,
      "learning_rate": 2.4435146443514645e-05,
      "loss": 0.4045,
      "step": 2980
    },
    {
      "epoch": 1.6076902393116428,
      "grad_norm": 14.462453842163086,
      "learning_rate": 2.4405260011954575e-05,
      "loss": 0.4274,
      "step": 2990
    },
    {
      "epoch": 1.6130680290400645,
      "grad_norm": 7.747549533843994,
      "learning_rate": 2.43753735803945e-05,
      "loss": 0.5112,
      "step": 3000
    },
    {
      "epoch": 1.6184458187684863,
      "grad_norm": 10.92934513092041,
      "learning_rate": 2.434548714883443e-05,
      "loss": 0.4623,
      "step": 3010
    },
    {
      "epoch": 1.6238236084969078,
      "grad_norm": 8.387574195861816,
      "learning_rate": 2.431560071727436e-05,
      "loss": 0.425,
      "step": 3020
    },
    {
      "epoch": 1.6292013982253293,
      "grad_norm": 11.540897369384766,
      "learning_rate": 2.4285714285714288e-05,
      "loss": 0.477,
      "step": 3030
    },
    {
      "epoch": 1.634579187953751,
      "grad_norm": 7.434033393859863,
      "learning_rate": 2.4255827854154217e-05,
      "loss": 0.4634,
      "step": 3040
    },
    {
      "epoch": 1.6399569776821727,
      "grad_norm": 5.982785224914551,
      "learning_rate": 2.4225941422594143e-05,
      "loss": 0.3869,
      "step": 3050
    },
    {
      "epoch": 1.6453347674105943,
      "grad_norm": 11.222881317138672,
      "learning_rate": 2.419605499103407e-05,
      "loss": 0.564,
      "step": 3060
    },
    {
      "epoch": 1.6507125571390158,
      "grad_norm": 6.796623229980469,
      "learning_rate": 2.4166168559473998e-05,
      "loss": 0.4519,
      "step": 3070
    },
    {
      "epoch": 1.6560903468674375,
      "grad_norm": 8.369091987609863,
      "learning_rate": 2.4136282127913927e-05,
      "loss": 0.4631,
      "step": 3080
    },
    {
      "epoch": 1.6614681365958592,
      "grad_norm": 10.662222862243652,
      "learning_rate": 2.4106395696353856e-05,
      "loss": 0.4672,
      "step": 3090
    },
    {
      "epoch": 1.6668459263242807,
      "grad_norm": 13.624146461486816,
      "learning_rate": 2.4076509264793785e-05,
      "loss": 0.375,
      "step": 3100
    },
    {
      "epoch": 1.6722237160527023,
      "grad_norm": 6.181455612182617,
      "learning_rate": 2.404662283323371e-05,
      "loss": 0.4088,
      "step": 3110
    },
    {
      "epoch": 1.677601505781124,
      "grad_norm": 10.841130256652832,
      "learning_rate": 2.401673640167364e-05,
      "loss": 0.3123,
      "step": 3120
    },
    {
      "epoch": 1.6829792955095457,
      "grad_norm": 12.077120780944824,
      "learning_rate": 2.398684997011357e-05,
      "loss": 0.4645,
      "step": 3130
    },
    {
      "epoch": 1.6883570852379672,
      "grad_norm": 12.557583808898926,
      "learning_rate": 2.39569635385535e-05,
      "loss": 0.5363,
      "step": 3140
    },
    {
      "epoch": 1.6937348749663887,
      "grad_norm": 9.441478729248047,
      "learning_rate": 2.3927077106993428e-05,
      "loss": 0.4317,
      "step": 3150
    },
    {
      "epoch": 1.6991126646948105,
      "grad_norm": 8.073275566101074,
      "learning_rate": 2.3897190675433354e-05,
      "loss": 0.4352,
      "step": 3160
    },
    {
      "epoch": 1.7044904544232322,
      "grad_norm": 13.17251968383789,
      "learning_rate": 2.3867304243873283e-05,
      "loss": 0.4225,
      "step": 3170
    },
    {
      "epoch": 1.7098682441516537,
      "grad_norm": 9.332930564880371,
      "learning_rate": 2.383741781231321e-05,
      "loss": 0.4239,
      "step": 3180
    },
    {
      "epoch": 1.7152460338800752,
      "grad_norm": 13.929574966430664,
      "learning_rate": 2.3807531380753138e-05,
      "loss": 0.4139,
      "step": 3190
    },
    {
      "epoch": 1.7206238236084967,
      "grad_norm": 9.51181411743164,
      "learning_rate": 2.3777644949193067e-05,
      "loss": 0.3604,
      "step": 3200
    },
    {
      "epoch": 1.7260016133369185,
      "grad_norm": 10.551231384277344,
      "learning_rate": 2.3747758517632993e-05,
      "loss": 0.4338,
      "step": 3210
    },
    {
      "epoch": 1.7313794030653402,
      "grad_norm": 7.949090003967285,
      "learning_rate": 2.3717872086072922e-05,
      "loss": 0.4983,
      "step": 3220
    },
    {
      "epoch": 1.7367571927937617,
      "grad_norm": 13.145767211914062,
      "learning_rate": 2.368798565451285e-05,
      "loss": 0.4742,
      "step": 3230
    },
    {
      "epoch": 1.7421349825221832,
      "grad_norm": 12.337911605834961,
      "learning_rate": 2.365809922295278e-05,
      "loss": 0.4138,
      "step": 3240
    },
    {
      "epoch": 1.747512772250605,
      "grad_norm": 4.641180992126465,
      "learning_rate": 2.362821279139271e-05,
      "loss": 0.309,
      "step": 3250
    },
    {
      "epoch": 1.7528905619790267,
      "grad_norm": 6.848506450653076,
      "learning_rate": 2.359832635983264e-05,
      "loss": 0.4105,
      "step": 3260
    },
    {
      "epoch": 1.7582683517074482,
      "grad_norm": 13.19502067565918,
      "learning_rate": 2.3568439928272565e-05,
      "loss": 0.3177,
      "step": 3270
    },
    {
      "epoch": 1.7636461414358697,
      "grad_norm": 6.78994083404541,
      "learning_rate": 2.3538553496712494e-05,
      "loss": 0.4046,
      "step": 3280
    },
    {
      "epoch": 1.7690239311642915,
      "grad_norm": 16.31090545654297,
      "learning_rate": 2.3508667065152423e-05,
      "loss": 0.4064,
      "step": 3290
    },
    {
      "epoch": 1.7744017208927132,
      "grad_norm": 11.790324211120605,
      "learning_rate": 2.3478780633592352e-05,
      "loss": 0.4109,
      "step": 3300
    },
    {
      "epoch": 1.7797795106211347,
      "grad_norm": 7.248150825500488,
      "learning_rate": 2.3448894202032278e-05,
      "loss": 0.442,
      "step": 3310
    },
    {
      "epoch": 1.7851573003495562,
      "grad_norm": 8.962907791137695,
      "learning_rate": 2.3419007770472204e-05,
      "loss": 0.4515,
      "step": 3320
    },
    {
      "epoch": 1.790535090077978,
      "grad_norm": 8.99335765838623,
      "learning_rate": 2.3389121338912133e-05,
      "loss": 0.3554,
      "step": 3330
    },
    {
      "epoch": 1.7959128798063997,
      "grad_norm": 9.868758201599121,
      "learning_rate": 2.3359234907352062e-05,
      "loss": 0.4778,
      "step": 3340
    },
    {
      "epoch": 1.8012906695348212,
      "grad_norm": 16.410306930541992,
      "learning_rate": 2.332934847579199e-05,
      "loss": 0.4263,
      "step": 3350
    },
    {
      "epoch": 1.8066684592632427,
      "grad_norm": 7.66259765625,
      "learning_rate": 2.329946204423192e-05,
      "loss": 0.3531,
      "step": 3360
    },
    {
      "epoch": 1.8120462489916644,
      "grad_norm": 8.851415634155273,
      "learning_rate": 2.3269575612671846e-05,
      "loss": 0.4109,
      "step": 3370
    },
    {
      "epoch": 1.8174240387200862,
      "grad_norm": 10.554017066955566,
      "learning_rate": 2.3239689181111775e-05,
      "loss": 0.4034,
      "step": 3380
    },
    {
      "epoch": 1.8228018284485077,
      "grad_norm": 8.339200019836426,
      "learning_rate": 2.3209802749551705e-05,
      "loss": 0.4676,
      "step": 3390
    },
    {
      "epoch": 1.8281796181769292,
      "grad_norm": 11.425588607788086,
      "learning_rate": 2.3179916317991634e-05,
      "loss": 0.4469,
      "step": 3400
    },
    {
      "epoch": 1.833557407905351,
      "grad_norm": 11.924715042114258,
      "learning_rate": 2.3150029886431563e-05,
      "loss": 0.4006,
      "step": 3410
    },
    {
      "epoch": 1.8389351976337727,
      "grad_norm": 9.854516983032227,
      "learning_rate": 2.312014345487149e-05,
      "loss": 0.3966,
      "step": 3420
    },
    {
      "epoch": 1.8443129873621942,
      "grad_norm": 12.676139831542969,
      "learning_rate": 2.3090257023311418e-05,
      "loss": 0.3364,
      "step": 3430
    },
    {
      "epoch": 1.8496907770906157,
      "grad_norm": 12.562860488891602,
      "learning_rate": 2.3060370591751344e-05,
      "loss": 0.3588,
      "step": 3440
    },
    {
      "epoch": 1.8550685668190374,
      "grad_norm": 12.32286548614502,
      "learning_rate": 2.3030484160191273e-05,
      "loss": 0.4221,
      "step": 3450
    },
    {
      "epoch": 1.8604463565474592,
      "grad_norm": 6.450922012329102,
      "learning_rate": 2.3000597728631202e-05,
      "loss": 0.384,
      "step": 3460
    },
    {
      "epoch": 1.8658241462758807,
      "grad_norm": 14.235567092895508,
      "learning_rate": 2.297071129707113e-05,
      "loss": 0.4134,
      "step": 3470
    },
    {
      "epoch": 1.8712019360043022,
      "grad_norm": 13.052252769470215,
      "learning_rate": 2.2940824865511057e-05,
      "loss": 0.3027,
      "step": 3480
    },
    {
      "epoch": 1.8765797257327237,
      "grad_norm": 14.366576194763184,
      "learning_rate": 2.2910938433950986e-05,
      "loss": 0.4097,
      "step": 3490
    },
    {
      "epoch": 1.8819575154611454,
      "grad_norm": 8.521063804626465,
      "learning_rate": 2.2881052002390915e-05,
      "loss": 0.4431,
      "step": 3500
    },
    {
      "epoch": 1.8873353051895672,
      "grad_norm": 8.175175666809082,
      "learning_rate": 2.2851165570830845e-05,
      "loss": 0.3268,
      "step": 3510
    },
    {
      "epoch": 1.8927130949179887,
      "grad_norm": 10.285233497619629,
      "learning_rate": 2.2821279139270774e-05,
      "loss": 0.3702,
      "step": 3520
    },
    {
      "epoch": 1.8980908846464102,
      "grad_norm": 14.090060234069824,
      "learning_rate": 2.27913927077107e-05,
      "loss": 0.3815,
      "step": 3530
    },
    {
      "epoch": 1.903468674374832,
      "grad_norm": 9.325505256652832,
      "learning_rate": 2.276150627615063e-05,
      "loss": 0.4103,
      "step": 3540
    },
    {
      "epoch": 1.9088464641032536,
      "grad_norm": 9.694278717041016,
      "learning_rate": 2.2731619844590558e-05,
      "loss": 0.3292,
      "step": 3550
    },
    {
      "epoch": 1.9142242538316752,
      "grad_norm": 8.932761192321777,
      "learning_rate": 2.2701733413030487e-05,
      "loss": 0.4333,
      "step": 3560
    },
    {
      "epoch": 1.9196020435600967,
      "grad_norm": 11.0848388671875,
      "learning_rate": 2.2671846981470413e-05,
      "loss": 0.3459,
      "step": 3570
    },
    {
      "epoch": 1.9249798332885184,
      "grad_norm": 11.352546691894531,
      "learning_rate": 2.264196054991034e-05,
      "loss": 0.3686,
      "step": 3580
    },
    {
      "epoch": 1.9303576230169401,
      "grad_norm": 8.077300071716309,
      "learning_rate": 2.2612074118350268e-05,
      "loss": 0.4698,
      "step": 3590
    },
    {
      "epoch": 1.9357354127453616,
      "grad_norm": 9.401605606079102,
      "learning_rate": 2.2582187686790197e-05,
      "loss": 0.3606,
      "step": 3600
    },
    {
      "epoch": 1.9411132024737832,
      "grad_norm": 6.728657245635986,
      "learning_rate": 2.2552301255230126e-05,
      "loss": 0.4342,
      "step": 3610
    },
    {
      "epoch": 1.946490992202205,
      "grad_norm": 8.43508243560791,
      "learning_rate": 2.2522414823670055e-05,
      "loss": 0.3152,
      "step": 3620
    },
    {
      "epoch": 1.9518687819306266,
      "grad_norm": 12.222505569458008,
      "learning_rate": 2.249252839210998e-05,
      "loss": 0.3671,
      "step": 3630
    },
    {
      "epoch": 1.9572465716590481,
      "grad_norm": 12.357940673828125,
      "learning_rate": 2.246264196054991e-05,
      "loss": 0.4887,
      "step": 3640
    },
    {
      "epoch": 1.9626243613874697,
      "grad_norm": 7.6261515617370605,
      "learning_rate": 2.243275552898984e-05,
      "loss": 0.3185,
      "step": 3650
    },
    {
      "epoch": 1.9680021511158914,
      "grad_norm": 11.105239868164062,
      "learning_rate": 2.240286909742977e-05,
      "loss": 0.3844,
      "step": 3660
    },
    {
      "epoch": 1.9733799408443131,
      "grad_norm": 11.552356719970703,
      "learning_rate": 2.2372982665869698e-05,
      "loss": 0.3265,
      "step": 3670
    },
    {
      "epoch": 1.9787577305727346,
      "grad_norm": 12.180983543395996,
      "learning_rate": 2.2343096234309624e-05,
      "loss": 0.4166,
      "step": 3680
    },
    {
      "epoch": 1.9841355203011561,
      "grad_norm": 11.146986961364746,
      "learning_rate": 2.2313209802749553e-05,
      "loss": 0.3441,
      "step": 3690
    },
    {
      "epoch": 1.9895133100295779,
      "grad_norm": 7.658456325531006,
      "learning_rate": 2.228332337118948e-05,
      "loss": 0.4104,
      "step": 3700
    },
    {
      "epoch": 1.9948910997579996,
      "grad_norm": 7.977283000946045,
      "learning_rate": 2.2253436939629408e-05,
      "loss": 0.4023,
      "step": 3710
    },
    {
      "epoch": 2.0,
      "grad_norm": 10.437973976135254,
      "learning_rate": 2.2223550508069337e-05,
      "loss": 0.3887,
      "step": 3720
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8494016404464165,
      "eval_f1": 0.8490425638552591,
      "eval_loss": 0.43158864974975586,
      "eval_runtime": 12.9085,
      "eval_samples_per_second": 1152.26,
      "eval_steps_per_second": 36.023,
      "step": 3720
    },
    {
      "epoch": 2.0053777897284215,
      "grad_norm": 11.949300765991211,
      "learning_rate": 2.2193664076509266e-05,
      "loss": 0.1795,
      "step": 3730
    },
    {
      "epoch": 2.010755579456843,
      "grad_norm": 8.530660629272461,
      "learning_rate": 2.2163777644949192e-05,
      "loss": 0.2015,
      "step": 3740
    },
    {
      "epoch": 2.016133369185265,
      "grad_norm": 9.735218048095703,
      "learning_rate": 2.213389121338912e-05,
      "loss": 0.2811,
      "step": 3750
    },
    {
      "epoch": 2.0215111589136865,
      "grad_norm": 11.202424049377441,
      "learning_rate": 2.210400478182905e-05,
      "loss": 0.2535,
      "step": 3760
    },
    {
      "epoch": 2.026888948642108,
      "grad_norm": 11.167068481445312,
      "learning_rate": 2.207411835026898e-05,
      "loss": 0.2528,
      "step": 3770
    },
    {
      "epoch": 2.0322667383705295,
      "grad_norm": 9.889775276184082,
      "learning_rate": 2.204423191870891e-05,
      "loss": 0.3407,
      "step": 3780
    },
    {
      "epoch": 2.0376445280989515,
      "grad_norm": 5.479250907897949,
      "learning_rate": 2.2014345487148835e-05,
      "loss": 0.2538,
      "step": 3790
    },
    {
      "epoch": 2.043022317827373,
      "grad_norm": 8.26517391204834,
      "learning_rate": 2.1984459055588764e-05,
      "loss": 0.3256,
      "step": 3800
    },
    {
      "epoch": 2.0484001075557945,
      "grad_norm": 5.08962345123291,
      "learning_rate": 2.1954572624028693e-05,
      "loss": 0.2649,
      "step": 3810
    },
    {
      "epoch": 2.053777897284216,
      "grad_norm": 7.36929988861084,
      "learning_rate": 2.1924686192468622e-05,
      "loss": 0.2384,
      "step": 3820
    },
    {
      "epoch": 2.059155687012638,
      "grad_norm": 3.784276247024536,
      "learning_rate": 2.1894799760908548e-05,
      "loss": 0.2376,
      "step": 3830
    },
    {
      "epoch": 2.0645334767410595,
      "grad_norm": 5.69965934753418,
      "learning_rate": 2.1864913329348474e-05,
      "loss": 0.2481,
      "step": 3840
    },
    {
      "epoch": 2.069911266469481,
      "grad_norm": 6.560776233673096,
      "learning_rate": 2.1835026897788403e-05,
      "loss": 0.242,
      "step": 3850
    },
    {
      "epoch": 2.0752890561979025,
      "grad_norm": 5.249701499938965,
      "learning_rate": 2.1805140466228332e-05,
      "loss": 0.2459,
      "step": 3860
    },
    {
      "epoch": 2.0806668459263244,
      "grad_norm": 2.63706111907959,
      "learning_rate": 2.177525403466826e-05,
      "loss": 0.2311,
      "step": 3870
    },
    {
      "epoch": 2.086044635654746,
      "grad_norm": 9.969863891601562,
      "learning_rate": 2.174536760310819e-05,
      "loss": 0.2317,
      "step": 3880
    },
    {
      "epoch": 2.0914224253831675,
      "grad_norm": 17.658037185668945,
      "learning_rate": 2.1715481171548116e-05,
      "loss": 0.2231,
      "step": 3890
    },
    {
      "epoch": 2.096800215111589,
      "grad_norm": 11.101682662963867,
      "learning_rate": 2.1685594739988045e-05,
      "loss": 0.2708,
      "step": 3900
    },
    {
      "epoch": 2.102178004840011,
      "grad_norm": 8.500958442687988,
      "learning_rate": 2.1655708308427975e-05,
      "loss": 0.2158,
      "step": 3910
    },
    {
      "epoch": 2.1075557945684325,
      "grad_norm": 11.116461753845215,
      "learning_rate": 2.1625821876867904e-05,
      "loss": 0.1893,
      "step": 3920
    },
    {
      "epoch": 2.112933584296854,
      "grad_norm": 8.695902824401855,
      "learning_rate": 2.1595935445307833e-05,
      "loss": 0.1963,
      "step": 3930
    },
    {
      "epoch": 2.1183113740252755,
      "grad_norm": 5.817938804626465,
      "learning_rate": 2.1566049013747762e-05,
      "loss": 0.2409,
      "step": 3940
    },
    {
      "epoch": 2.1236891637536974,
      "grad_norm": 4.51364278793335,
      "learning_rate": 2.1536162582187688e-05,
      "loss": 0.208,
      "step": 3950
    },
    {
      "epoch": 2.129066953482119,
      "grad_norm": 10.332389831542969,
      "learning_rate": 2.1506276150627614e-05,
      "loss": 0.2138,
      "step": 3960
    },
    {
      "epoch": 2.1344447432105405,
      "grad_norm": 7.984367847442627,
      "learning_rate": 2.1476389719067543e-05,
      "loss": 0.2516,
      "step": 3970
    },
    {
      "epoch": 2.139822532938962,
      "grad_norm": 10.325634002685547,
      "learning_rate": 2.1446503287507472e-05,
      "loss": 0.2912,
      "step": 3980
    },
    {
      "epoch": 2.1452003226673835,
      "grad_norm": 6.773406028747559,
      "learning_rate": 2.14166168559474e-05,
      "loss": 0.239,
      "step": 3990
    },
    {
      "epoch": 2.1505781123958054,
      "grad_norm": 6.9003729820251465,
      "learning_rate": 2.1386730424387327e-05,
      "loss": 0.211,
      "step": 4000
    },
    {
      "epoch": 2.155955902124227,
      "grad_norm": 15.8524808883667,
      "learning_rate": 2.1356843992827256e-05,
      "loss": 0.2227,
      "step": 4010
    },
    {
      "epoch": 2.1613336918526485,
      "grad_norm": 15.705512046813965,
      "learning_rate": 2.1326957561267185e-05,
      "loss": 0.2251,
      "step": 4020
    },
    {
      "epoch": 2.1667114815810704,
      "grad_norm": 11.771419525146484,
      "learning_rate": 2.1297071129707115e-05,
      "loss": 0.2667,
      "step": 4030
    },
    {
      "epoch": 2.172089271309492,
      "grad_norm": 11.720993041992188,
      "learning_rate": 2.1267184698147044e-05,
      "loss": 0.1815,
      "step": 4040
    },
    {
      "epoch": 2.1774670610379134,
      "grad_norm": 9.347159385681152,
      "learning_rate": 2.123729826658697e-05,
      "loss": 0.2481,
      "step": 4050
    },
    {
      "epoch": 2.182844850766335,
      "grad_norm": 7.451066970825195,
      "learning_rate": 2.12074118350269e-05,
      "loss": 0.2131,
      "step": 4060
    },
    {
      "epoch": 2.1882226404947565,
      "grad_norm": 14.670979499816895,
      "learning_rate": 2.1177525403466828e-05,
      "loss": 0.1647,
      "step": 4070
    },
    {
      "epoch": 2.1936004302231784,
      "grad_norm": 15.78321647644043,
      "learning_rate": 2.1147638971906754e-05,
      "loss": 0.229,
      "step": 4080
    },
    {
      "epoch": 2.1989782199516,
      "grad_norm": 6.829586029052734,
      "learning_rate": 2.1117752540346683e-05,
      "loss": 0.3402,
      "step": 4090
    },
    {
      "epoch": 2.2043560096800214,
      "grad_norm": 7.856372356414795,
      "learning_rate": 2.108786610878661e-05,
      "loss": 0.2461,
      "step": 4100
    },
    {
      "epoch": 2.209733799408443,
      "grad_norm": 16.60474395751953,
      "learning_rate": 2.1057979677226538e-05,
      "loss": 0.2286,
      "step": 4110
    },
    {
      "epoch": 2.215111589136865,
      "grad_norm": 1.843772292137146,
      "learning_rate": 2.1028093245666467e-05,
      "loss": 0.2402,
      "step": 4120
    },
    {
      "epoch": 2.2204893788652864,
      "grad_norm": 7.115623474121094,
      "learning_rate": 2.0998206814106396e-05,
      "loss": 0.2426,
      "step": 4130
    },
    {
      "epoch": 2.225867168593708,
      "grad_norm": 11.045315742492676,
      "learning_rate": 2.0968320382546325e-05,
      "loss": 0.2884,
      "step": 4140
    },
    {
      "epoch": 2.2312449583221294,
      "grad_norm": 23.79228401184082,
      "learning_rate": 2.0938433950986255e-05,
      "loss": 0.2389,
      "step": 4150
    },
    {
      "epoch": 2.2366227480505514,
      "grad_norm": 10.189345359802246,
      "learning_rate": 2.090854751942618e-05,
      "loss": 0.2561,
      "step": 4160
    },
    {
      "epoch": 2.242000537778973,
      "grad_norm": 10.296760559082031,
      "learning_rate": 2.087866108786611e-05,
      "loss": 0.1996,
      "step": 4170
    },
    {
      "epoch": 2.2473783275073944,
      "grad_norm": 11.560770034790039,
      "learning_rate": 2.084877465630604e-05,
      "loss": 0.1642,
      "step": 4180
    },
    {
      "epoch": 2.252756117235816,
      "grad_norm": 8.544143676757812,
      "learning_rate": 2.0818888224745968e-05,
      "loss": 0.2916,
      "step": 4190
    },
    {
      "epoch": 2.258133906964238,
      "grad_norm": 8.059098243713379,
      "learning_rate": 2.0789001793185897e-05,
      "loss": 0.3536,
      "step": 4200
    },
    {
      "epoch": 2.2635116966926594,
      "grad_norm": 7.2315239906311035,
      "learning_rate": 2.0759115361625823e-05,
      "loss": 0.3181,
      "step": 4210
    },
    {
      "epoch": 2.268889486421081,
      "grad_norm": 13.202797889709473,
      "learning_rate": 2.072922893006575e-05,
      "loss": 0.2871,
      "step": 4220
    },
    {
      "epoch": 2.2742672761495024,
      "grad_norm": 16.976625442504883,
      "learning_rate": 2.0699342498505678e-05,
      "loss": 0.2063,
      "step": 4230
    },
    {
      "epoch": 2.279645065877924,
      "grad_norm": 2.8299331665039062,
      "learning_rate": 2.0669456066945607e-05,
      "loss": 0.2714,
      "step": 4240
    },
    {
      "epoch": 2.285022855606346,
      "grad_norm": 12.807461738586426,
      "learning_rate": 2.0639569635385536e-05,
      "loss": 0.2685,
      "step": 4250
    },
    {
      "epoch": 2.2904006453347674,
      "grad_norm": 8.068925857543945,
      "learning_rate": 2.0609683203825462e-05,
      "loss": 0.2012,
      "step": 4260
    },
    {
      "epoch": 2.295778435063189,
      "grad_norm": 8.836767196655273,
      "learning_rate": 2.057979677226539e-05,
      "loss": 0.2342,
      "step": 4270
    },
    {
      "epoch": 2.301156224791611,
      "grad_norm": 16.350811004638672,
      "learning_rate": 2.054991034070532e-05,
      "loss": 0.2064,
      "step": 4280
    },
    {
      "epoch": 2.3065340145200324,
      "grad_norm": 11.637167930603027,
      "learning_rate": 2.052002390914525e-05,
      "loss": 0.2624,
      "step": 4290
    },
    {
      "epoch": 2.311911804248454,
      "grad_norm": 5.565012454986572,
      "learning_rate": 2.049013747758518e-05,
      "loss": 0.2256,
      "step": 4300
    },
    {
      "epoch": 2.3172895939768754,
      "grad_norm": 14.121227264404297,
      "learning_rate": 2.0460251046025104e-05,
      "loss": 0.3295,
      "step": 4310
    },
    {
      "epoch": 2.322667383705297,
      "grad_norm": 16.505535125732422,
      "learning_rate": 2.0430364614465034e-05,
      "loss": 0.2883,
      "step": 4320
    },
    {
      "epoch": 2.328045173433719,
      "grad_norm": 14.796144485473633,
      "learning_rate": 2.0400478182904963e-05,
      "loss": 0.2555,
      "step": 4330
    },
    {
      "epoch": 2.3334229631621404,
      "grad_norm": 11.194036483764648,
      "learning_rate": 2.037059175134489e-05,
      "loss": 0.2481,
      "step": 4340
    },
    {
      "epoch": 2.338800752890562,
      "grad_norm": 8.630349159240723,
      "learning_rate": 2.0340705319784818e-05,
      "loss": 0.2661,
      "step": 4350
    },
    {
      "epoch": 2.344178542618984,
      "grad_norm": 9.872974395751953,
      "learning_rate": 2.0310818888224747e-05,
      "loss": 0.1511,
      "step": 4360
    },
    {
      "epoch": 2.3495563323474054,
      "grad_norm": 7.212757110595703,
      "learning_rate": 2.0280932456664673e-05,
      "loss": 0.2059,
      "step": 4370
    },
    {
      "epoch": 2.354934122075827,
      "grad_norm": 10.080791473388672,
      "learning_rate": 2.0251046025104602e-05,
      "loss": 0.1859,
      "step": 4380
    },
    {
      "epoch": 2.3603119118042484,
      "grad_norm": 5.3862481117248535,
      "learning_rate": 2.022115959354453e-05,
      "loss": 0.2253,
      "step": 4390
    },
    {
      "epoch": 2.36568970153267,
      "grad_norm": 11.390453338623047,
      "learning_rate": 2.019127316198446e-05,
      "loss": 0.1925,
      "step": 4400
    },
    {
      "epoch": 2.371067491261092,
      "grad_norm": 8.560564041137695,
      "learning_rate": 2.016138673042439e-05,
      "loss": 0.2745,
      "step": 4410
    },
    {
      "epoch": 2.3764452809895134,
      "grad_norm": 11.255148887634277,
      "learning_rate": 2.0131500298864315e-05,
      "loss": 0.2296,
      "step": 4420
    },
    {
      "epoch": 2.381823070717935,
      "grad_norm": 7.580559730529785,
      "learning_rate": 2.0101613867304244e-05,
      "loss": 0.1988,
      "step": 4430
    },
    {
      "epoch": 2.3872008604463564,
      "grad_norm": 1.7152962684631348,
      "learning_rate": 2.0071727435744174e-05,
      "loss": 0.2297,
      "step": 4440
    },
    {
      "epoch": 2.3925786501747783,
      "grad_norm": 11.885425567626953,
      "learning_rate": 2.0041841004184103e-05,
      "loss": 0.2783,
      "step": 4450
    },
    {
      "epoch": 2.3979564399032,
      "grad_norm": 6.217536926269531,
      "learning_rate": 2.0011954572624032e-05,
      "loss": 0.1923,
      "step": 4460
    },
    {
      "epoch": 2.4033342296316214,
      "grad_norm": 14.410941123962402,
      "learning_rate": 1.9982068141063954e-05,
      "loss": 0.1983,
      "step": 4470
    },
    {
      "epoch": 2.408712019360043,
      "grad_norm": 14.613525390625,
      "learning_rate": 1.9952181709503884e-05,
      "loss": 0.2684,
      "step": 4480
    },
    {
      "epoch": 2.414089809088465,
      "grad_norm": 3.5234408378601074,
      "learning_rate": 1.9922295277943813e-05,
      "loss": 0.2131,
      "step": 4490
    },
    {
      "epoch": 2.4194675988168863,
      "grad_norm": 1.7131390571594238,
      "learning_rate": 1.9892408846383742e-05,
      "loss": 0.2011,
      "step": 4500
    },
    {
      "epoch": 2.424845388545308,
      "grad_norm": 9.759147644042969,
      "learning_rate": 1.986252241482367e-05,
      "loss": 0.2267,
      "step": 4510
    },
    {
      "epoch": 2.4302231782737294,
      "grad_norm": 11.101618766784668,
      "learning_rate": 1.9832635983263597e-05,
      "loss": 0.1764,
      "step": 4520
    },
    {
      "epoch": 2.4356009680021513,
      "grad_norm": 14.537829399108887,
      "learning_rate": 1.9802749551703526e-05,
      "loss": 0.245,
      "step": 4530
    },
    {
      "epoch": 2.440978757730573,
      "grad_norm": 12.690718650817871,
      "learning_rate": 1.9772863120143455e-05,
      "loss": 0.2243,
      "step": 4540
    },
    {
      "epoch": 2.4463565474589943,
      "grad_norm": 10.927294731140137,
      "learning_rate": 1.9742976688583384e-05,
      "loss": 0.2613,
      "step": 4550
    },
    {
      "epoch": 2.451734337187416,
      "grad_norm": 13.696186065673828,
      "learning_rate": 1.9713090257023314e-05,
      "loss": 0.1878,
      "step": 4560
    },
    {
      "epoch": 2.4571121269158374,
      "grad_norm": 9.004582405090332,
      "learning_rate": 1.9683203825463243e-05,
      "loss": 0.2338,
      "step": 4570
    },
    {
      "epoch": 2.4624899166442593,
      "grad_norm": 14.51038932800293,
      "learning_rate": 1.965331739390317e-05,
      "loss": 0.2333,
      "step": 4580
    },
    {
      "epoch": 2.467867706372681,
      "grad_norm": 16.85088348388672,
      "learning_rate": 1.9623430962343098e-05,
      "loss": 0.1844,
      "step": 4590
    },
    {
      "epoch": 2.4732454961011023,
      "grad_norm": 15.546272277832031,
      "learning_rate": 1.9593544530783024e-05,
      "loss": 0.2634,
      "step": 4600
    },
    {
      "epoch": 2.4786232858295243,
      "grad_norm": 5.118035793304443,
      "learning_rate": 1.9563658099222953e-05,
      "loss": 0.241,
      "step": 4610
    },
    {
      "epoch": 2.484001075557946,
      "grad_norm": 9.020153045654297,
      "learning_rate": 1.9533771667662882e-05,
      "loss": 0.214,
      "step": 4620
    },
    {
      "epoch": 2.4893788652863673,
      "grad_norm": 8.796299934387207,
      "learning_rate": 1.9503885236102808e-05,
      "loss": 0.1852,
      "step": 4630
    },
    {
      "epoch": 2.494756655014789,
      "grad_norm": 14.58509349822998,
      "learning_rate": 1.9473998804542737e-05,
      "loss": 0.3248,
      "step": 4640
    },
    {
      "epoch": 2.5001344447432103,
      "grad_norm": 7.3610968589782715,
      "learning_rate": 1.9444112372982666e-05,
      "loss": 0.2193,
      "step": 4650
    },
    {
      "epoch": 2.5055122344716323,
      "grad_norm": 15.4872407913208,
      "learning_rate": 1.9414225941422595e-05,
      "loss": 0.2203,
      "step": 4660
    },
    {
      "epoch": 2.510890024200054,
      "grad_norm": 15.858907699584961,
      "learning_rate": 1.9384339509862524e-05,
      "loss": 0.1966,
      "step": 4670
    },
    {
      "epoch": 2.5162678139284753,
      "grad_norm": 10.972484588623047,
      "learning_rate": 1.935445307830245e-05,
      "loss": 0.2516,
      "step": 4680
    },
    {
      "epoch": 2.5216456036568973,
      "grad_norm": 7.658966064453125,
      "learning_rate": 1.932456664674238e-05,
      "loss": 0.1808,
      "step": 4690
    },
    {
      "epoch": 2.527023393385319,
      "grad_norm": 4.518768310546875,
      "learning_rate": 1.929468021518231e-05,
      "loss": 0.2089,
      "step": 4700
    },
    {
      "epoch": 2.5324011831137403,
      "grad_norm": 17.227317810058594,
      "learning_rate": 1.9264793783622238e-05,
      "loss": 0.1706,
      "step": 4710
    },
    {
      "epoch": 2.537778972842162,
      "grad_norm": 17.446996688842773,
      "learning_rate": 1.9234907352062167e-05,
      "loss": 0.2478,
      "step": 4720
    },
    {
      "epoch": 2.5431567625705833,
      "grad_norm": 3.984320640563965,
      "learning_rate": 1.920502092050209e-05,
      "loss": 0.1816,
      "step": 4730
    },
    {
      "epoch": 2.5485345522990053,
      "grad_norm": 1.9649258852005005,
      "learning_rate": 1.917513448894202e-05,
      "loss": 0.151,
      "step": 4740
    },
    {
      "epoch": 2.553912342027427,
      "grad_norm": 0.7069669961929321,
      "learning_rate": 1.9145248057381948e-05,
      "loss": 0.1836,
      "step": 4750
    },
    {
      "epoch": 2.5592901317558483,
      "grad_norm": 8.81810474395752,
      "learning_rate": 1.9115361625821877e-05,
      "loss": 0.2717,
      "step": 4760
    },
    {
      "epoch": 2.56466792148427,
      "grad_norm": 15.1983642578125,
      "learning_rate": 1.9088463837417813e-05,
      "loss": 0.2362,
      "step": 4770
    },
    {
      "epoch": 2.5700457112126918,
      "grad_norm": 5.578619003295898,
      "learning_rate": 1.905857740585774e-05,
      "loss": 0.1736,
      "step": 4780
    },
    {
      "epoch": 2.5754235009411133,
      "grad_norm": 13.718754768371582,
      "learning_rate": 1.9028690974297668e-05,
      "loss": 0.1533,
      "step": 4790
    },
    {
      "epoch": 2.580801290669535,
      "grad_norm": 9.966392517089844,
      "learning_rate": 1.8998804542737597e-05,
      "loss": 0.2064,
      "step": 4800
    },
    {
      "epoch": 2.5861790803979563,
      "grad_norm": 9.196101188659668,
      "learning_rate": 1.8968918111177526e-05,
      "loss": 0.2135,
      "step": 4810
    },
    {
      "epoch": 2.591556870126378,
      "grad_norm": 14.739230155944824,
      "learning_rate": 1.8939031679617455e-05,
      "loss": 0.1776,
      "step": 4820
    },
    {
      "epoch": 2.5969346598547998,
      "grad_norm": 13.007439613342285,
      "learning_rate": 1.890914524805738e-05,
      "loss": 0.2747,
      "step": 4830
    },
    {
      "epoch": 2.6023124495832213,
      "grad_norm": 15.416919708251953,
      "learning_rate": 1.887925881649731e-05,
      "loss": 0.2339,
      "step": 4840
    },
    {
      "epoch": 2.607690239311643,
      "grad_norm": 4.895371913909912,
      "learning_rate": 1.884937238493724e-05,
      "loss": 0.2502,
      "step": 4850
    },
    {
      "epoch": 2.6130680290400647,
      "grad_norm": 10.809305191040039,
      "learning_rate": 1.881948595337717e-05,
      "loss": 0.216,
      "step": 4860
    },
    {
      "epoch": 2.6184458187684863,
      "grad_norm": 25.88155746459961,
      "learning_rate": 1.8789599521817098e-05,
      "loss": 0.2056,
      "step": 4870
    },
    {
      "epoch": 2.6238236084969078,
      "grad_norm": 11.404061317443848,
      "learning_rate": 1.8759713090257024e-05,
      "loss": 0.212,
      "step": 4880
    },
    {
      "epoch": 2.6292013982253293,
      "grad_norm": 17.86648941040039,
      "learning_rate": 1.8729826658696953e-05,
      "loss": 0.2541,
      "step": 4890
    },
    {
      "epoch": 2.634579187953751,
      "grad_norm": 15.395535469055176,
      "learning_rate": 1.869994022713688e-05,
      "loss": 0.1978,
      "step": 4900
    },
    {
      "epoch": 2.6399569776821727,
      "grad_norm": 3.9343199729919434,
      "learning_rate": 1.8670053795576808e-05,
      "loss": 0.1978,
      "step": 4910
    },
    {
      "epoch": 2.6453347674105943,
      "grad_norm": 14.99754810333252,
      "learning_rate": 1.8640167364016737e-05,
      "loss": 0.1981,
      "step": 4920
    },
    {
      "epoch": 2.6507125571390158,
      "grad_norm": 4.0431437492370605,
      "learning_rate": 1.8610280932456663e-05,
      "loss": 0.1561,
      "step": 4930
    },
    {
      "epoch": 2.6560903468674377,
      "grad_norm": 13.097091674804688,
      "learning_rate": 1.8580394500896592e-05,
      "loss": 0.2645,
      "step": 4940
    },
    {
      "epoch": 2.6614681365958592,
      "grad_norm": 14.066551208496094,
      "learning_rate": 1.855050806933652e-05,
      "loss": 0.2227,
      "step": 4950
    },
    {
      "epoch": 2.6668459263242807,
      "grad_norm": 12.571702003479004,
      "learning_rate": 1.852062163777645e-05,
      "loss": 0.2654,
      "step": 4960
    },
    {
      "epoch": 2.6722237160527023,
      "grad_norm": 7.54707145690918,
      "learning_rate": 1.849073520621638e-05,
      "loss": 0.228,
      "step": 4970
    },
    {
      "epoch": 2.6776015057811238,
      "grad_norm": 8.578489303588867,
      "learning_rate": 1.846084877465631e-05,
      "loss": 0.2511,
      "step": 4980
    },
    {
      "epoch": 2.6829792955095457,
      "grad_norm": 17.16815948486328,
      "learning_rate": 1.8430962343096234e-05,
      "loss": 0.199,
      "step": 4990
    },
    {
      "epoch": 2.6883570852379672,
      "grad_norm": 9.315110206604004,
      "learning_rate": 1.8401075911536164e-05,
      "loss": 0.2248,
      "step": 5000
    },
    {
      "epoch": 2.6937348749663887,
      "grad_norm": 4.524838924407959,
      "learning_rate": 1.8371189479976093e-05,
      "loss": 0.1932,
      "step": 5010
    },
    {
      "epoch": 2.6991126646948107,
      "grad_norm": 11.453184127807617,
      "learning_rate": 1.8341303048416022e-05,
      "loss": 0.1804,
      "step": 5020
    },
    {
      "epoch": 2.704490454423232,
      "grad_norm": 8.116602897644043,
      "learning_rate": 1.8311416616855948e-05,
      "loss": 0.1653,
      "step": 5030
    },
    {
      "epoch": 2.7098682441516537,
      "grad_norm": 1.7617489099502563,
      "learning_rate": 1.8281530185295874e-05,
      "loss": 0.246,
      "step": 5040
    },
    {
      "epoch": 2.7152460338800752,
      "grad_norm": 9.832869529724121,
      "learning_rate": 1.8251643753735803e-05,
      "loss": 0.1714,
      "step": 5050
    },
    {
      "epoch": 2.7206238236084967,
      "grad_norm": 11.679574012756348,
      "learning_rate": 1.8221757322175732e-05,
      "loss": 0.2347,
      "step": 5060
    },
    {
      "epoch": 2.7260016133369183,
      "grad_norm": 5.2382426261901855,
      "learning_rate": 1.819187089061566e-05,
      "loss": 0.1383,
      "step": 5070
    },
    {
      "epoch": 2.73137940306534,
      "grad_norm": 5.541048049926758,
      "learning_rate": 1.816198445905559e-05,
      "loss": 0.1613,
      "step": 5080
    },
    {
      "epoch": 2.7367571927937617,
      "grad_norm": 14.875007629394531,
      "learning_rate": 1.8132098027495516e-05,
      "loss": 0.1642,
      "step": 5090
    },
    {
      "epoch": 2.7421349825221832,
      "grad_norm": 15.21955680847168,
      "learning_rate": 1.8102211595935445e-05,
      "loss": 0.2008,
      "step": 5100
    },
    {
      "epoch": 2.747512772250605,
      "grad_norm": 10.548645973205566,
      "learning_rate": 1.8072325164375374e-05,
      "loss": 0.2494,
      "step": 5110
    },
    {
      "epoch": 2.7528905619790267,
      "grad_norm": 13.223251342773438,
      "learning_rate": 1.8042438732815304e-05,
      "loss": 0.2084,
      "step": 5120
    },
    {
      "epoch": 2.758268351707448,
      "grad_norm": 23.132638931274414,
      "learning_rate": 1.8012552301255233e-05,
      "loss": 0.2523,
      "step": 5130
    },
    {
      "epoch": 2.7636461414358697,
      "grad_norm": 15.294229507446289,
      "learning_rate": 1.798266586969516e-05,
      "loss": 0.1583,
      "step": 5140
    },
    {
      "epoch": 2.7690239311642912,
      "grad_norm": 10.462934494018555,
      "learning_rate": 1.7952779438135088e-05,
      "loss": 0.2462,
      "step": 5150
    },
    {
      "epoch": 2.774401720892713,
      "grad_norm": 11.086043357849121,
      "learning_rate": 1.7922893006575014e-05,
      "loss": 0.2245,
      "step": 5160
    },
    {
      "epoch": 2.7797795106211347,
      "grad_norm": 9.46010971069336,
      "learning_rate": 1.7893006575014943e-05,
      "loss": 0.1507,
      "step": 5170
    },
    {
      "epoch": 2.785157300349556,
      "grad_norm": 3.1213505268096924,
      "learning_rate": 1.7863120143454872e-05,
      "loss": 0.1976,
      "step": 5180
    },
    {
      "epoch": 2.790535090077978,
      "grad_norm": 6.941793918609619,
      "learning_rate": 1.7833233711894798e-05,
      "loss": 0.2182,
      "step": 5190
    },
    {
      "epoch": 2.7959128798063997,
      "grad_norm": 6.9846415519714355,
      "learning_rate": 1.7803347280334727e-05,
      "loss": 0.2023,
      "step": 5200
    },
    {
      "epoch": 2.801290669534821,
      "grad_norm": 10.810077667236328,
      "learning_rate": 1.7773460848774656e-05,
      "loss": 0.1576,
      "step": 5210
    },
    {
      "epoch": 2.8066684592632427,
      "grad_norm": 14.401269912719727,
      "learning_rate": 1.7743574417214585e-05,
      "loss": 0.1334,
      "step": 5220
    },
    {
      "epoch": 2.812046248991664,
      "grad_norm": 10.841689109802246,
      "learning_rate": 1.7713687985654514e-05,
      "loss": 0.1997,
      "step": 5230
    },
    {
      "epoch": 2.817424038720086,
      "grad_norm": 22.0238037109375,
      "learning_rate": 1.7683801554094444e-05,
      "loss": 0.2283,
      "step": 5240
    },
    {
      "epoch": 2.8228018284485077,
      "grad_norm": 20.081571578979492,
      "learning_rate": 1.765391512253437e-05,
      "loss": 0.2389,
      "step": 5250
    },
    {
      "epoch": 2.828179618176929,
      "grad_norm": 12.453259468078613,
      "learning_rate": 1.76240286909743e-05,
      "loss": 0.1529,
      "step": 5260
    },
    {
      "epoch": 2.833557407905351,
      "grad_norm": 16.29248809814453,
      "learning_rate": 1.7594142259414228e-05,
      "loss": 0.1774,
      "step": 5270
    },
    {
      "epoch": 2.8389351976337727,
      "grad_norm": 10.718541145324707,
      "learning_rate": 1.7564255827854157e-05,
      "loss": 0.2136,
      "step": 5280
    },
    {
      "epoch": 2.844312987362194,
      "grad_norm": 13.424652099609375,
      "learning_rate": 1.7534369396294083e-05,
      "loss": 0.2311,
      "step": 5290
    },
    {
      "epoch": 2.8496907770906157,
      "grad_norm": 15.670762062072754,
      "learning_rate": 1.750448296473401e-05,
      "loss": 0.2243,
      "step": 5300
    },
    {
      "epoch": 2.855068566819037,
      "grad_norm": 8.988189697265625,
      "learning_rate": 1.7474596533173938e-05,
      "loss": 0.3155,
      "step": 5310
    },
    {
      "epoch": 2.860446356547459,
      "grad_norm": 10.2290678024292,
      "learning_rate": 1.7444710101613867e-05,
      "loss": 0.2247,
      "step": 5320
    },
    {
      "epoch": 2.8658241462758807,
      "grad_norm": 18.282634735107422,
      "learning_rate": 1.7414823670053796e-05,
      "loss": 0.2977,
      "step": 5330
    },
    {
      "epoch": 2.871201936004302,
      "grad_norm": 17.74856948852539,
      "learning_rate": 1.7384937238493725e-05,
      "loss": 0.1948,
      "step": 5340
    },
    {
      "epoch": 2.8765797257327237,
      "grad_norm": 20.75384521484375,
      "learning_rate": 1.735505080693365e-05,
      "loss": 0.1717,
      "step": 5350
    },
    {
      "epoch": 2.8819575154611456,
      "grad_norm": 7.445942401885986,
      "learning_rate": 1.732516437537358e-05,
      "loss": 0.3023,
      "step": 5360
    },
    {
      "epoch": 2.887335305189567,
      "grad_norm": 3.250692844390869,
      "learning_rate": 1.729527794381351e-05,
      "loss": 0.2078,
      "step": 5370
    },
    {
      "epoch": 2.8927130949179887,
      "grad_norm": 5.352571487426758,
      "learning_rate": 1.726539151225344e-05,
      "loss": 0.1711,
      "step": 5380
    },
    {
      "epoch": 2.89809088464641,
      "grad_norm": 5.76071834564209,
      "learning_rate": 1.7235505080693368e-05,
      "loss": 0.2295,
      "step": 5390
    },
    {
      "epoch": 2.9034686743748317,
      "grad_norm": 10.80649185180664,
      "learning_rate": 1.7205618649133294e-05,
      "loss": 0.1712,
      "step": 5400
    },
    {
      "epoch": 2.9088464641032536,
      "grad_norm": 12.238947868347168,
      "learning_rate": 1.7175732217573223e-05,
      "loss": 0.23,
      "step": 5410
    },
    {
      "epoch": 2.914224253831675,
      "grad_norm": 2.1307761669158936,
      "learning_rate": 1.714584578601315e-05,
      "loss": 0.2333,
      "step": 5420
    },
    {
      "epoch": 2.9196020435600967,
      "grad_norm": 8.680463790893555,
      "learning_rate": 1.7115959354453078e-05,
      "loss": 0.2307,
      "step": 5430
    },
    {
      "epoch": 2.9249798332885186,
      "grad_norm": 13.598913192749023,
      "learning_rate": 1.7086072922893007e-05,
      "loss": 0.1751,
      "step": 5440
    },
    {
      "epoch": 2.93035762301694,
      "grad_norm": 7.964286804199219,
      "learning_rate": 1.7056186491332936e-05,
      "loss": 0.2105,
      "step": 5450
    },
    {
      "epoch": 2.9357354127453616,
      "grad_norm": 6.805628776550293,
      "learning_rate": 1.7026300059772862e-05,
      "loss": 0.2084,
      "step": 5460
    },
    {
      "epoch": 2.941113202473783,
      "grad_norm": 9.028409957885742,
      "learning_rate": 1.699641362821279e-05,
      "loss": 0.2635,
      "step": 5470
    },
    {
      "epoch": 2.9464909922022047,
      "grad_norm": 10.993341445922852,
      "learning_rate": 1.696652719665272e-05,
      "loss": 0.2372,
      "step": 5480
    },
    {
      "epoch": 2.9518687819306266,
      "grad_norm": 14.72192668914795,
      "learning_rate": 1.693664076509265e-05,
      "loss": 0.2209,
      "step": 5490
    },
    {
      "epoch": 2.957246571659048,
      "grad_norm": 14.32662582397461,
      "learning_rate": 1.690675433353258e-05,
      "loss": 0.185,
      "step": 5500
    },
    {
      "epoch": 2.9626243613874697,
      "grad_norm": 8.904743194580078,
      "learning_rate": 1.6876867901972504e-05,
      "loss": 0.1992,
      "step": 5510
    },
    {
      "epoch": 2.9680021511158916,
      "grad_norm": 17.067670822143555,
      "learning_rate": 1.6846981470412434e-05,
      "loss": 0.1624,
      "step": 5520
    },
    {
      "epoch": 2.973379940844313,
      "grad_norm": 12.921652793884277,
      "learning_rate": 1.6817095038852363e-05,
      "loss": 0.1989,
      "step": 5530
    },
    {
      "epoch": 2.9787577305727346,
      "grad_norm": 4.652234077453613,
      "learning_rate": 1.6787208607292292e-05,
      "loss": 0.1519,
      "step": 5540
    },
    {
      "epoch": 2.984135520301156,
      "grad_norm": 5.058923244476318,
      "learning_rate": 1.6757322175732218e-05,
      "loss": 0.16,
      "step": 5550
    },
    {
      "epoch": 2.9895133100295777,
      "grad_norm": 24.941850662231445,
      "learning_rate": 1.6727435744172144e-05,
      "loss": 0.1907,
      "step": 5560
    },
    {
      "epoch": 2.9948910997579996,
      "grad_norm": 11.0924711227417,
      "learning_rate": 1.6697549312612073e-05,
      "loss": 0.2449,
      "step": 5570
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.6945157051086426,
      "learning_rate": 1.6667662881052002e-05,
      "loss": 0.1482,
      "step": 5580
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.8820761059567029,
      "eval_f1": 0.8821558794079972,
      "eval_loss": 0.37087592482566833,
      "eval_runtime": 12.926,
      "eval_samples_per_second": 1150.701,
      "eval_steps_per_second": 35.974,
      "step": 5580
    },
    {
      "epoch": 3.0053777897284215,
      "grad_norm": 6.816864967346191,
      "learning_rate": 1.663777644949193e-05,
      "loss": 0.1383,
      "step": 5590
    },
    {
      "epoch": 3.010755579456843,
      "grad_norm": 4.509511470794678,
      "learning_rate": 1.660789001793186e-05,
      "loss": 0.1726,
      "step": 5600
    },
    {
      "epoch": 3.016133369185265,
      "grad_norm": 19.38132667541504,
      "learning_rate": 1.6578003586371786e-05,
      "loss": 0.1214,
      "step": 5610
    },
    {
      "epoch": 3.0215111589136865,
      "grad_norm": 12.251612663269043,
      "learning_rate": 1.6548117154811715e-05,
      "loss": 0.1209,
      "step": 5620
    },
    {
      "epoch": 3.026888948642108,
      "grad_norm": 14.584393501281738,
      "learning_rate": 1.6518230723251644e-05,
      "loss": 0.0976,
      "step": 5630
    },
    {
      "epoch": 3.0322667383705295,
      "grad_norm": 2.0886576175689697,
      "learning_rate": 1.6488344291691574e-05,
      "loss": 0.1085,
      "step": 5640
    },
    {
      "epoch": 3.0376445280989515,
      "grad_norm": 13.82448959350586,
      "learning_rate": 1.6458457860131503e-05,
      "loss": 0.1517,
      "step": 5650
    },
    {
      "epoch": 3.043022317827373,
      "grad_norm": 2.1404378414154053,
      "learning_rate": 1.6428571428571432e-05,
      "loss": 0.147,
      "step": 5660
    },
    {
      "epoch": 3.0484001075557945,
      "grad_norm": 9.926316261291504,
      "learning_rate": 1.6398684997011358e-05,
      "loss": 0.1167,
      "step": 5670
    },
    {
      "epoch": 3.053777897284216,
      "grad_norm": 22.676029205322266,
      "learning_rate": 1.6368798565451284e-05,
      "loss": 0.1173,
      "step": 5680
    },
    {
      "epoch": 3.059155687012638,
      "grad_norm": 1.3834125995635986,
      "learning_rate": 1.6338912133891213e-05,
      "loss": 0.1245,
      "step": 5690
    },
    {
      "epoch": 3.0645334767410595,
      "grad_norm": 27.059541702270508,
      "learning_rate": 1.6309025702331142e-05,
      "loss": 0.153,
      "step": 5700
    },
    {
      "epoch": 3.069911266469481,
      "grad_norm": 10.07726764678955,
      "learning_rate": 1.627913927077107e-05,
      "loss": 0.1353,
      "step": 5710
    },
    {
      "epoch": 3.0752890561979025,
      "grad_norm": 1.0173792839050293,
      "learning_rate": 1.6249252839210997e-05,
      "loss": 0.1502,
      "step": 5720
    },
    {
      "epoch": 3.0806668459263244,
      "grad_norm": 16.308359146118164,
      "learning_rate": 1.6219366407650926e-05,
      "loss": 0.1239,
      "step": 5730
    },
    {
      "epoch": 3.086044635654746,
      "grad_norm": 10.666401863098145,
      "learning_rate": 1.6189479976090855e-05,
      "loss": 0.1699,
      "step": 5740
    },
    {
      "epoch": 3.0914224253831675,
      "grad_norm": 0.7738609910011292,
      "learning_rate": 1.6159593544530784e-05,
      "loss": 0.1549,
      "step": 5750
    },
    {
      "epoch": 3.096800215111589,
      "grad_norm": 10.209278106689453,
      "learning_rate": 1.6129707112970714e-05,
      "loss": 0.171,
      "step": 5760
    },
    {
      "epoch": 3.102178004840011,
      "grad_norm": 6.055801868438721,
      "learning_rate": 1.609982068141064e-05,
      "loss": 0.1222,
      "step": 5770
    },
    {
      "epoch": 3.1075557945684325,
      "grad_norm": 0.936138391494751,
      "learning_rate": 1.606993424985057e-05,
      "loss": 0.1473,
      "step": 5780
    },
    {
      "epoch": 3.112933584296854,
      "grad_norm": 1.5984764099121094,
      "learning_rate": 1.6040047818290498e-05,
      "loss": 0.1364,
      "step": 5790
    },
    {
      "epoch": 3.1183113740252755,
      "grad_norm": 3.245170831680298,
      "learning_rate": 1.6010161386730427e-05,
      "loss": 0.1056,
      "step": 5800
    },
    {
      "epoch": 3.1236891637536974,
      "grad_norm": 1.8700432777404785,
      "learning_rate": 1.5980274955170353e-05,
      "loss": 0.1077,
      "step": 5810
    },
    {
      "epoch": 3.129066953482119,
      "grad_norm": 4.148591995239258,
      "learning_rate": 1.595038852361028e-05,
      "loss": 0.1543,
      "step": 5820
    },
    {
      "epoch": 3.1344447432105405,
      "grad_norm": 10.727784156799316,
      "learning_rate": 1.5920502092050208e-05,
      "loss": 0.1411,
      "step": 5830
    },
    {
      "epoch": 3.139822532938962,
      "grad_norm": 5.367246627807617,
      "learning_rate": 1.5890615660490137e-05,
      "loss": 0.1123,
      "step": 5840
    },
    {
      "epoch": 3.1452003226673835,
      "grad_norm": 16.44942855834961,
      "learning_rate": 1.5860729228930066e-05,
      "loss": 0.0765,
      "step": 5850
    },
    {
      "epoch": 3.1505781123958054,
      "grad_norm": 12.39185619354248,
      "learning_rate": 1.5830842797369995e-05,
      "loss": 0.1172,
      "step": 5860
    },
    {
      "epoch": 3.155955902124227,
      "grad_norm": 2.819978952407837,
      "learning_rate": 1.5800956365809924e-05,
      "loss": 0.1453,
      "step": 5870
    },
    {
      "epoch": 3.1613336918526485,
      "grad_norm": 15.571410179138184,
      "learning_rate": 1.577106993424985e-05,
      "loss": 0.1104,
      "step": 5880
    },
    {
      "epoch": 3.1667114815810704,
      "grad_norm": 8.38723373413086,
      "learning_rate": 1.574118350268978e-05,
      "loss": 0.1431,
      "step": 5890
    },
    {
      "epoch": 3.172089271309492,
      "grad_norm": 11.280359268188477,
      "learning_rate": 1.571129707112971e-05,
      "loss": 0.2032,
      "step": 5900
    },
    {
      "epoch": 3.1774670610379134,
      "grad_norm": 1.805203914642334,
      "learning_rate": 1.5681410639569638e-05,
      "loss": 0.1551,
      "step": 5910
    },
    {
      "epoch": 3.182844850766335,
      "grad_norm": 5.782737731933594,
      "learning_rate": 1.5651524208009567e-05,
      "loss": 0.1359,
      "step": 5920
    },
    {
      "epoch": 3.1882226404947565,
      "grad_norm": 2.521613597869873,
      "learning_rate": 1.5621637776449493e-05,
      "loss": 0.1312,
      "step": 5930
    },
    {
      "epoch": 3.1936004302231784,
      "grad_norm": 10.608726501464844,
      "learning_rate": 1.559175134488942e-05,
      "loss": 0.2092,
      "step": 5940
    },
    {
      "epoch": 3.1989782199516,
      "grad_norm": 15.673064231872559,
      "learning_rate": 1.5561864913329348e-05,
      "loss": 0.162,
      "step": 5950
    },
    {
      "epoch": 3.2043560096800214,
      "grad_norm": 16.780487060546875,
      "learning_rate": 1.5531978481769277e-05,
      "loss": 0.1894,
      "step": 5960
    },
    {
      "epoch": 3.209733799408443,
      "grad_norm": 7.189998149871826,
      "learning_rate": 1.5502092050209206e-05,
      "loss": 0.1008,
      "step": 5970
    },
    {
      "epoch": 3.215111589136865,
      "grad_norm": 11.193828582763672,
      "learning_rate": 1.5472205618649132e-05,
      "loss": 0.1184,
      "step": 5980
    },
    {
      "epoch": 3.2204893788652864,
      "grad_norm": 2.9559521675109863,
      "learning_rate": 1.544231918708906e-05,
      "loss": 0.1015,
      "step": 5990
    },
    {
      "epoch": 3.225867168593708,
      "grad_norm": 20.1651668548584,
      "learning_rate": 1.541243275552899e-05,
      "loss": 0.1155,
      "step": 6000
    },
    {
      "epoch": 3.2312449583221294,
      "grad_norm": 6.407525539398193,
      "learning_rate": 1.538254632396892e-05,
      "loss": 0.1457,
      "step": 6010
    },
    {
      "epoch": 3.2366227480505514,
      "grad_norm": 7.524753570556641,
      "learning_rate": 1.535265989240885e-05,
      "loss": 0.1083,
      "step": 6020
    },
    {
      "epoch": 3.242000537778973,
      "grad_norm": 24.68199348449707,
      "learning_rate": 1.5322773460848774e-05,
      "loss": 0.1418,
      "step": 6030
    },
    {
      "epoch": 3.2473783275073944,
      "grad_norm": 3.6403884887695312,
      "learning_rate": 1.5292887029288704e-05,
      "loss": 0.1486,
      "step": 6040
    },
    {
      "epoch": 3.252756117235816,
      "grad_norm": 19.188068389892578,
      "learning_rate": 1.5263000597728633e-05,
      "loss": 0.1512,
      "step": 6050
    },
    {
      "epoch": 3.258133906964238,
      "grad_norm": 13.851505279541016,
      "learning_rate": 1.523311416616856e-05,
      "loss": 0.1518,
      "step": 6060
    },
    {
      "epoch": 3.2635116966926594,
      "grad_norm": 12.520777702331543,
      "learning_rate": 1.520322773460849e-05,
      "loss": 0.127,
      "step": 6070
    },
    {
      "epoch": 3.268889486421081,
      "grad_norm": 4.867264270782471,
      "learning_rate": 1.5173341303048419e-05,
      "loss": 0.1553,
      "step": 6080
    },
    {
      "epoch": 3.2742672761495024,
      "grad_norm": 11.473204612731934,
      "learning_rate": 1.5143454871488344e-05,
      "loss": 0.1222,
      "step": 6090
    },
    {
      "epoch": 3.279645065877924,
      "grad_norm": 0.8541625142097473,
      "learning_rate": 1.5113568439928272e-05,
      "loss": 0.2118,
      "step": 6100
    },
    {
      "epoch": 3.285022855606346,
      "grad_norm": 13.47963809967041,
      "learning_rate": 1.5083682008368201e-05,
      "loss": 0.181,
      "step": 6110
    },
    {
      "epoch": 3.2904006453347674,
      "grad_norm": 18.433002471923828,
      "learning_rate": 1.505379557680813e-05,
      "loss": 0.1193,
      "step": 6120
    },
    {
      "epoch": 3.295778435063189,
      "grad_norm": 1.1779953241348267,
      "learning_rate": 1.502390914524806e-05,
      "loss": 0.1375,
      "step": 6130
    },
    {
      "epoch": 3.301156224791611,
      "grad_norm": 14.503002166748047,
      "learning_rate": 1.4994022713687987e-05,
      "loss": 0.1363,
      "step": 6140
    },
    {
      "epoch": 3.3065340145200324,
      "grad_norm": 3.5428991317749023,
      "learning_rate": 1.4964136282127914e-05,
      "loss": 0.1215,
      "step": 6150
    },
    {
      "epoch": 3.311911804248454,
      "grad_norm": 3.2861783504486084,
      "learning_rate": 1.4934249850567842e-05,
      "loss": 0.0969,
      "step": 6160
    },
    {
      "epoch": 3.3172895939768754,
      "grad_norm": 6.69209623336792,
      "learning_rate": 1.4904363419007771e-05,
      "loss": 0.167,
      "step": 6170
    },
    {
      "epoch": 3.322667383705297,
      "grad_norm": 0.46278175711631775,
      "learning_rate": 1.4874476987447699e-05,
      "loss": 0.1689,
      "step": 6180
    },
    {
      "epoch": 3.328045173433719,
      "grad_norm": 22.037118911743164,
      "learning_rate": 1.4844590555887628e-05,
      "loss": 0.0941,
      "step": 6190
    },
    {
      "epoch": 3.3334229631621404,
      "grad_norm": 14.228474617004395,
      "learning_rate": 1.4814704124327555e-05,
      "loss": 0.1419,
      "step": 6200
    },
    {
      "epoch": 3.338800752890562,
      "grad_norm": 12.30394458770752,
      "learning_rate": 1.4784817692767484e-05,
      "loss": 0.1099,
      "step": 6210
    },
    {
      "epoch": 3.344178542618984,
      "grad_norm": 14.955267906188965,
      "learning_rate": 1.4754931261207414e-05,
      "loss": 0.1591,
      "step": 6220
    },
    {
      "epoch": 3.3495563323474054,
      "grad_norm": 5.944122314453125,
      "learning_rate": 1.472504482964734e-05,
      "loss": 0.0899,
      "step": 6230
    },
    {
      "epoch": 3.354934122075827,
      "grad_norm": 11.213692665100098,
      "learning_rate": 1.4695158398087269e-05,
      "loss": 0.13,
      "step": 6240
    },
    {
      "epoch": 3.3603119118042484,
      "grad_norm": 4.130800247192383,
      "learning_rate": 1.4665271966527198e-05,
      "loss": 0.1284,
      "step": 6250
    },
    {
      "epoch": 3.36568970153267,
      "grad_norm": 0.7727387547492981,
      "learning_rate": 1.4635385534967125e-05,
      "loss": 0.1267,
      "step": 6260
    },
    {
      "epoch": 3.371067491261092,
      "grad_norm": 10.945947647094727,
      "learning_rate": 1.4605499103407054e-05,
      "loss": 0.1293,
      "step": 6270
    },
    {
      "epoch": 3.3764452809895134,
      "grad_norm": 12.530179977416992,
      "learning_rate": 1.4575612671846982e-05,
      "loss": 0.1596,
      "step": 6280
    },
    {
      "epoch": 3.381823070717935,
      "grad_norm": 8.152948379516602,
      "learning_rate": 1.454572624028691e-05,
      "loss": 0.0759,
      "step": 6290
    },
    {
      "epoch": 3.3872008604463564,
      "grad_norm": 4.07595157623291,
      "learning_rate": 1.4515839808726839e-05,
      "loss": 0.1376,
      "step": 6300
    },
    {
      "epoch": 3.3925786501747783,
      "grad_norm": 7.276675224304199,
      "learning_rate": 1.4485953377166766e-05,
      "loss": 0.1503,
      "step": 6310
    },
    {
      "epoch": 3.3979564399032,
      "grad_norm": 1.9925870895385742,
      "learning_rate": 1.4456066945606695e-05,
      "loss": 0.118,
      "step": 6320
    },
    {
      "epoch": 3.4033342296316214,
      "grad_norm": 3.343142509460449,
      "learning_rate": 1.4426180514046623e-05,
      "loss": 0.1538,
      "step": 6330
    },
    {
      "epoch": 3.408712019360043,
      "grad_norm": 17.951618194580078,
      "learning_rate": 1.4396294082486552e-05,
      "loss": 0.0972,
      "step": 6340
    },
    {
      "epoch": 3.414089809088465,
      "grad_norm": 0.6488545536994934,
      "learning_rate": 1.4366407650926481e-05,
      "loss": 0.1563,
      "step": 6350
    },
    {
      "epoch": 3.4194675988168863,
      "grad_norm": 3.6599068641662598,
      "learning_rate": 1.4336521219366407e-05,
      "loss": 0.1663,
      "step": 6360
    },
    {
      "epoch": 3.424845388545308,
      "grad_norm": 14.14560317993164,
      "learning_rate": 1.4306634787806336e-05,
      "loss": 0.0973,
      "step": 6370
    },
    {
      "epoch": 3.4302231782737294,
      "grad_norm": 0.818067729473114,
      "learning_rate": 1.4276748356246265e-05,
      "loss": 0.1739,
      "step": 6380
    },
    {
      "epoch": 3.4356009680021513,
      "grad_norm": 14.05119800567627,
      "learning_rate": 1.4246861924686193e-05,
      "loss": 0.1687,
      "step": 6390
    },
    {
      "epoch": 3.440978757730573,
      "grad_norm": 6.8730854988098145,
      "learning_rate": 1.4216975493126122e-05,
      "loss": 0.0863,
      "step": 6400
    },
    {
      "epoch": 3.4463565474589943,
      "grad_norm": 0.13102996349334717,
      "learning_rate": 1.418708906156605e-05,
      "loss": 0.071,
      "step": 6410
    },
    {
      "epoch": 3.451734337187416,
      "grad_norm": 2.9093058109283447,
      "learning_rate": 1.4157202630005977e-05,
      "loss": 0.1621,
      "step": 6420
    },
    {
      "epoch": 3.4571121269158374,
      "grad_norm": 15.374221801757812,
      "learning_rate": 1.4127316198445906e-05,
      "loss": 0.1843,
      "step": 6430
    },
    {
      "epoch": 3.4624899166442593,
      "grad_norm": 14.984756469726562,
      "learning_rate": 1.4097429766885834e-05,
      "loss": 0.1789,
      "step": 6440
    },
    {
      "epoch": 3.467867706372681,
      "grad_norm": 15.501049995422363,
      "learning_rate": 1.4067543335325763e-05,
      "loss": 0.1592,
      "step": 6450
    },
    {
      "epoch": 3.4732454961011023,
      "grad_norm": 1.0232001543045044,
      "learning_rate": 1.4037656903765692e-05,
      "loss": 0.1253,
      "step": 6460
    },
    {
      "epoch": 3.4786232858295243,
      "grad_norm": 1.4504165649414062,
      "learning_rate": 1.400777047220562e-05,
      "loss": 0.1711,
      "step": 6470
    },
    {
      "epoch": 3.484001075557946,
      "grad_norm": 13.570886611938477,
      "learning_rate": 1.3977884040645549e-05,
      "loss": 0.0851,
      "step": 6480
    },
    {
      "epoch": 3.4893788652863673,
      "grad_norm": 9.795485496520996,
      "learning_rate": 1.3947997609085474e-05,
      "loss": 0.1067,
      "step": 6490
    },
    {
      "epoch": 3.494756655014789,
      "grad_norm": 9.66295337677002,
      "learning_rate": 1.3918111177525404e-05,
      "loss": 0.1646,
      "step": 6500
    },
    {
      "epoch": 3.5001344447432103,
      "grad_norm": 7.808931350708008,
      "learning_rate": 1.3888224745965333e-05,
      "loss": 0.0695,
      "step": 6510
    },
    {
      "epoch": 3.5055122344716323,
      "grad_norm": 6.469095706939697,
      "learning_rate": 1.385833831440526e-05,
      "loss": 0.1126,
      "step": 6520
    },
    {
      "epoch": 3.510890024200054,
      "grad_norm": 17.145341873168945,
      "learning_rate": 1.382845188284519e-05,
      "loss": 0.165,
      "step": 6530
    },
    {
      "epoch": 3.5162678139284753,
      "grad_norm": 20.595476150512695,
      "learning_rate": 1.3798565451285117e-05,
      "loss": 0.1544,
      "step": 6540
    },
    {
      "epoch": 3.5216456036568973,
      "grad_norm": 3.13185977935791,
      "learning_rate": 1.3768679019725044e-05,
      "loss": 0.1461,
      "step": 6550
    },
    {
      "epoch": 3.527023393385319,
      "grad_norm": 6.256194591522217,
      "learning_rate": 1.3738792588164974e-05,
      "loss": 0.134,
      "step": 6560
    },
    {
      "epoch": 3.5324011831137403,
      "grad_norm": 3.1600112915039062,
      "learning_rate": 1.3708906156604901e-05,
      "loss": 0.1507,
      "step": 6570
    },
    {
      "epoch": 3.537778972842162,
      "grad_norm": 8.275358200073242,
      "learning_rate": 1.367901972504483e-05,
      "loss": 0.1265,
      "step": 6580
    },
    {
      "epoch": 3.5431567625705833,
      "grad_norm": 8.158658981323242,
      "learning_rate": 1.364913329348476e-05,
      "loss": 0.1821,
      "step": 6590
    },
    {
      "epoch": 3.5485345522990053,
      "grad_norm": 21.503196716308594,
      "learning_rate": 1.3619246861924687e-05,
      "loss": 0.1388,
      "step": 6600
    },
    {
      "epoch": 3.553912342027427,
      "grad_norm": 6.0247111320495605,
      "learning_rate": 1.3589360430364614e-05,
      "loss": 0.1928,
      "step": 6610
    },
    {
      "epoch": 3.5592901317558483,
      "grad_norm": 6.849100112915039,
      "learning_rate": 1.3559473998804542e-05,
      "loss": 0.097,
      "step": 6620
    },
    {
      "epoch": 3.56466792148427,
      "grad_norm": 8.13295841217041,
      "learning_rate": 1.3529587567244471e-05,
      "loss": 0.1198,
      "step": 6630
    },
    {
      "epoch": 3.5700457112126918,
      "grad_norm": 12.178465843200684,
      "learning_rate": 1.34997011356844e-05,
      "loss": 0.1218,
      "step": 6640
    },
    {
      "epoch": 3.5754235009411133,
      "grad_norm": 7.496109962463379,
      "learning_rate": 1.3469814704124328e-05,
      "loss": 0.1195,
      "step": 6650
    },
    {
      "epoch": 3.580801290669535,
      "grad_norm": 6.039641380310059,
      "learning_rate": 1.3439928272564257e-05,
      "loss": 0.1369,
      "step": 6660
    },
    {
      "epoch": 3.5861790803979563,
      "grad_norm": 5.9592719078063965,
      "learning_rate": 1.3410041841004184e-05,
      "loss": 0.1516,
      "step": 6670
    },
    {
      "epoch": 3.591556870126378,
      "grad_norm": 20.23656463623047,
      "learning_rate": 1.3380155409444112e-05,
      "loss": 0.144,
      "step": 6680
    },
    {
      "epoch": 3.5969346598547998,
      "grad_norm": 4.977140426635742,
      "learning_rate": 1.3350268977884041e-05,
      "loss": 0.1347,
      "step": 6690
    },
    {
      "epoch": 3.6023124495832213,
      "grad_norm": 3.0467913150787354,
      "learning_rate": 1.3320382546323968e-05,
      "loss": 0.0978,
      "step": 6700
    },
    {
      "epoch": 3.607690239311643,
      "grad_norm": 1.291536808013916,
      "learning_rate": 1.3290496114763898e-05,
      "loss": 0.0738,
      "step": 6710
    },
    {
      "epoch": 3.6130680290400647,
      "grad_norm": 10.668702125549316,
      "learning_rate": 1.3260609683203827e-05,
      "loss": 0.2196,
      "step": 6720
    },
    {
      "epoch": 3.6184458187684863,
      "grad_norm": 29.37955093383789,
      "learning_rate": 1.3230723251643754e-05,
      "loss": 0.1839,
      "step": 6730
    },
    {
      "epoch": 3.6238236084969078,
      "grad_norm": 8.43478012084961,
      "learning_rate": 1.3200836820083682e-05,
      "loss": 0.2008,
      "step": 6740
    },
    {
      "epoch": 3.6292013982253293,
      "grad_norm": 0.8296425938606262,
      "learning_rate": 1.317095038852361e-05,
      "loss": 0.1281,
      "step": 6750
    },
    {
      "epoch": 3.634579187953751,
      "grad_norm": 12.44448184967041,
      "learning_rate": 1.3141063956963538e-05,
      "loss": 0.1458,
      "step": 6760
    },
    {
      "epoch": 3.6399569776821727,
      "grad_norm": 1.8012349605560303,
      "learning_rate": 1.3111177525403468e-05,
      "loss": 0.1036,
      "step": 6770
    },
    {
      "epoch": 3.6453347674105943,
      "grad_norm": 13.1710205078125,
      "learning_rate": 1.3081291093843395e-05,
      "loss": 0.13,
      "step": 6780
    },
    {
      "epoch": 3.6507125571390158,
      "grad_norm": 4.67697811126709,
      "learning_rate": 1.3051404662283324e-05,
      "loss": 0.1541,
      "step": 6790
    },
    {
      "epoch": 3.6560903468674377,
      "grad_norm": 7.312776565551758,
      "learning_rate": 1.3021518230723254e-05,
      "loss": 0.1952,
      "step": 6800
    },
    {
      "epoch": 3.6614681365958592,
      "grad_norm": 2.7128796577453613,
      "learning_rate": 1.299163179916318e-05,
      "loss": 0.1123,
      "step": 6810
    },
    {
      "epoch": 3.6668459263242807,
      "grad_norm": 9.35719108581543,
      "learning_rate": 1.2961745367603108e-05,
      "loss": 0.1129,
      "step": 6820
    },
    {
      "epoch": 3.6722237160527023,
      "grad_norm": 1.569352149963379,
      "learning_rate": 1.2931858936043036e-05,
      "loss": 0.1809,
      "step": 6830
    },
    {
      "epoch": 3.6776015057811238,
      "grad_norm": 2.0270822048187256,
      "learning_rate": 1.2901972504482965e-05,
      "loss": 0.0915,
      "step": 6840
    },
    {
      "epoch": 3.6829792955095457,
      "grad_norm": 4.033847332000732,
      "learning_rate": 1.2872086072922894e-05,
      "loss": 0.1178,
      "step": 6850
    },
    {
      "epoch": 3.6883570852379672,
      "grad_norm": 8.926640510559082,
      "learning_rate": 1.2842199641362822e-05,
      "loss": 0.1153,
      "step": 6860
    },
    {
      "epoch": 3.6937348749663887,
      "grad_norm": 22.499704360961914,
      "learning_rate": 1.281231320980275e-05,
      "loss": 0.2021,
      "step": 6870
    },
    {
      "epoch": 3.6991126646948107,
      "grad_norm": 5.766498565673828,
      "learning_rate": 1.2782426778242677e-05,
      "loss": 0.1795,
      "step": 6880
    },
    {
      "epoch": 3.704490454423232,
      "grad_norm": 1.7352774143218994,
      "learning_rate": 1.2752540346682606e-05,
      "loss": 0.1643,
      "step": 6890
    },
    {
      "epoch": 3.7098682441516537,
      "grad_norm": 3.8601863384246826,
      "learning_rate": 1.2722653915122535e-05,
      "loss": 0.136,
      "step": 6900
    },
    {
      "epoch": 3.7152460338800752,
      "grad_norm": 12.651917457580566,
      "learning_rate": 1.2692767483562463e-05,
      "loss": 0.1129,
      "step": 6910
    },
    {
      "epoch": 3.7206238236084967,
      "grad_norm": 3.945819854736328,
      "learning_rate": 1.2662881052002392e-05,
      "loss": 0.1365,
      "step": 6920
    },
    {
      "epoch": 3.7260016133369183,
      "grad_norm": 5.124084949493408,
      "learning_rate": 1.2632994620442321e-05,
      "loss": 0.1993,
      "step": 6930
    },
    {
      "epoch": 3.73137940306534,
      "grad_norm": 5.7185821533203125,
      "learning_rate": 1.2603108188882247e-05,
      "loss": 0.1152,
      "step": 6940
    },
    {
      "epoch": 3.7367571927937617,
      "grad_norm": 8.578902244567871,
      "learning_rate": 1.2573221757322176e-05,
      "loss": 0.1689,
      "step": 6950
    },
    {
      "epoch": 3.7421349825221832,
      "grad_norm": 6.8536577224731445,
      "learning_rate": 1.2543335325762103e-05,
      "loss": 0.1962,
      "step": 6960
    },
    {
      "epoch": 3.747512772250605,
      "grad_norm": 1.555471420288086,
      "learning_rate": 1.2513448894202033e-05,
      "loss": 0.1472,
      "step": 6970
    },
    {
      "epoch": 3.7528905619790267,
      "grad_norm": 4.008901119232178,
      "learning_rate": 1.2483562462641962e-05,
      "loss": 0.1355,
      "step": 6980
    },
    {
      "epoch": 3.758268351707448,
      "grad_norm": 10.536215782165527,
      "learning_rate": 1.245367603108189e-05,
      "loss": 0.1551,
      "step": 6990
    },
    {
      "epoch": 3.7636461414358697,
      "grad_norm": Infinity,
      "learning_rate": 1.2426778242677825e-05,
      "loss": 0.1355,
      "step": 7000
    },
    {
      "epoch": 3.7690239311642912,
      "grad_norm": 30.956214904785156,
      "learning_rate": 1.2396891811117753e-05,
      "loss": 0.1675,
      "step": 7010
    },
    {
      "epoch": 3.774401720892713,
      "grad_norm": 1.9960424900054932,
      "learning_rate": 1.2367005379557682e-05,
      "loss": 0.1585,
      "step": 7020
    },
    {
      "epoch": 3.7797795106211347,
      "grad_norm": 2.641428232192993,
      "learning_rate": 1.233711894799761e-05,
      "loss": 0.1269,
      "step": 7030
    },
    {
      "epoch": 3.785157300349556,
      "grad_norm": 8.983281135559082,
      "learning_rate": 1.2307232516437537e-05,
      "loss": 0.1476,
      "step": 7040
    },
    {
      "epoch": 3.790535090077978,
      "grad_norm": 13.295552253723145,
      "learning_rate": 1.2277346084877466e-05,
      "loss": 0.1209,
      "step": 7050
    },
    {
      "epoch": 3.7959128798063997,
      "grad_norm": 0.8059808611869812,
      "learning_rate": 1.2247459653317394e-05,
      "loss": 0.1437,
      "step": 7060
    },
    {
      "epoch": 3.801290669534821,
      "grad_norm": 5.63515567779541,
      "learning_rate": 1.2217573221757323e-05,
      "loss": 0.1213,
      "step": 7070
    },
    {
      "epoch": 3.8066684592632427,
      "grad_norm": 19.577245712280273,
      "learning_rate": 1.218768679019725e-05,
      "loss": 0.0995,
      "step": 7080
    },
    {
      "epoch": 3.812046248991664,
      "grad_norm": 7.14221715927124,
      "learning_rate": 1.215780035863718e-05,
      "loss": 0.116,
      "step": 7090
    },
    {
      "epoch": 3.817424038720086,
      "grad_norm": 4.063560485839844,
      "learning_rate": 1.2127913927077109e-05,
      "loss": 0.128,
      "step": 7100
    },
    {
      "epoch": 3.8228018284485077,
      "grad_norm": 10.05070972442627,
      "learning_rate": 1.2098027495517034e-05,
      "loss": 0.1707,
      "step": 7110
    },
    {
      "epoch": 3.828179618176929,
      "grad_norm": 8.8538236618042,
      "learning_rate": 1.2068141063956964e-05,
      "loss": 0.1076,
      "step": 7120
    },
    {
      "epoch": 3.833557407905351,
      "grad_norm": 17.201688766479492,
      "learning_rate": 1.2038254632396893e-05,
      "loss": 0.1857,
      "step": 7130
    },
    {
      "epoch": 3.8389351976337727,
      "grad_norm": 18.817520141601562,
      "learning_rate": 1.200836820083682e-05,
      "loss": 0.1579,
      "step": 7140
    },
    {
      "epoch": 3.844312987362194,
      "grad_norm": 11.524161338806152,
      "learning_rate": 1.197848176927675e-05,
      "loss": 0.1452,
      "step": 7150
    },
    {
      "epoch": 3.8496907770906157,
      "grad_norm": 22.543317794799805,
      "learning_rate": 1.1948595337716677e-05,
      "loss": 0.1494,
      "step": 7160
    },
    {
      "epoch": 3.855068566819037,
      "grad_norm": 9.340142250061035,
      "learning_rate": 1.1918708906156604e-05,
      "loss": 0.1454,
      "step": 7170
    },
    {
      "epoch": 3.860446356547459,
      "grad_norm": 0.8713726997375488,
      "learning_rate": 1.1888822474596534e-05,
      "loss": 0.1869,
      "step": 7180
    },
    {
      "epoch": 3.8658241462758807,
      "grad_norm": 9.596988677978516,
      "learning_rate": 1.1858936043036461e-05,
      "loss": 0.1892,
      "step": 7190
    },
    {
      "epoch": 3.871201936004302,
      "grad_norm": 2.3740956783294678,
      "learning_rate": 1.182904961147639e-05,
      "loss": 0.1449,
      "step": 7200
    },
    {
      "epoch": 3.8765797257327237,
      "grad_norm": 3.477217197418213,
      "learning_rate": 1.179916317991632e-05,
      "loss": 0.122,
      "step": 7210
    },
    {
      "epoch": 3.8819575154611456,
      "grad_norm": 10.135368347167969,
      "learning_rate": 1.1769276748356247e-05,
      "loss": 0.1399,
      "step": 7220
    },
    {
      "epoch": 3.887335305189567,
      "grad_norm": 3.307286262512207,
      "learning_rate": 1.1739390316796176e-05,
      "loss": 0.179,
      "step": 7230
    },
    {
      "epoch": 3.8927130949179887,
      "grad_norm": 4.232217311859131,
      "learning_rate": 1.1709503885236102e-05,
      "loss": 0.1649,
      "step": 7240
    },
    {
      "epoch": 3.89809088464641,
      "grad_norm": 1.8761523962020874,
      "learning_rate": 1.1679617453676031e-05,
      "loss": 0.0978,
      "step": 7250
    },
    {
      "epoch": 3.9034686743748317,
      "grad_norm": 19.38359260559082,
      "learning_rate": 1.164973102211596e-05,
      "loss": 0.1057,
      "step": 7260
    },
    {
      "epoch": 3.9088464641032536,
      "grad_norm": 1.6669995784759521,
      "learning_rate": 1.1619844590555888e-05,
      "loss": 0.1906,
      "step": 7270
    },
    {
      "epoch": 3.914224253831675,
      "grad_norm": 1.2500526905059814,
      "learning_rate": 1.1589958158995817e-05,
      "loss": 0.0969,
      "step": 7280
    },
    {
      "epoch": 3.9196020435600967,
      "grad_norm": 10.659586906433105,
      "learning_rate": 1.1560071727435744e-05,
      "loss": 0.1196,
      "step": 7290
    },
    {
      "epoch": 3.9249798332885186,
      "grad_norm": 13.307572364807129,
      "learning_rate": 1.1530185295875672e-05,
      "loss": 0.1527,
      "step": 7300
    },
    {
      "epoch": 3.93035762301694,
      "grad_norm": 2.5342535972595215,
      "learning_rate": 1.1500298864315601e-05,
      "loss": 0.1056,
      "step": 7310
    },
    {
      "epoch": 3.9357354127453616,
      "grad_norm": 12.30493450164795,
      "learning_rate": 1.1470412432755529e-05,
      "loss": 0.1411,
      "step": 7320
    },
    {
      "epoch": 3.941113202473783,
      "grad_norm": 1.806228518486023,
      "learning_rate": 1.1440526001195458e-05,
      "loss": 0.1256,
      "step": 7330
    },
    {
      "epoch": 3.9464909922022047,
      "grad_norm": 7.683681011199951,
      "learning_rate": 1.1410639569635387e-05,
      "loss": 0.1835,
      "step": 7340
    },
    {
      "epoch": 3.9518687819306266,
      "grad_norm": 11.379971504211426,
      "learning_rate": 1.1380753138075314e-05,
      "loss": 0.1182,
      "step": 7350
    },
    {
      "epoch": 3.957246571659048,
      "grad_norm": 0.8367149233818054,
      "learning_rate": 1.1350866706515244e-05,
      "loss": 0.1256,
      "step": 7360
    },
    {
      "epoch": 3.9626243613874697,
      "grad_norm": 16.837947845458984,
      "learning_rate": 1.132098027495517e-05,
      "loss": 0.12,
      "step": 7370
    },
    {
      "epoch": 3.9680021511158916,
      "grad_norm": 7.942272186279297,
      "learning_rate": 1.1291093843395099e-05,
      "loss": 0.1049,
      "step": 7380
    },
    {
      "epoch": 3.973379940844313,
      "grad_norm": 15.350160598754883,
      "learning_rate": 1.1261207411835028e-05,
      "loss": 0.1054,
      "step": 7390
    },
    {
      "epoch": 3.9787577305727346,
      "grad_norm": 9.920058250427246,
      "learning_rate": 1.1231320980274955e-05,
      "loss": 0.1196,
      "step": 7400
    },
    {
      "epoch": 3.984135520301156,
      "grad_norm": 4.088724613189697,
      "learning_rate": 1.1201434548714884e-05,
      "loss": 0.1416,
      "step": 7410
    },
    {
      "epoch": 3.9895133100295777,
      "grad_norm": 0.8761664628982544,
      "learning_rate": 1.1171548117154812e-05,
      "loss": 0.1036,
      "step": 7420
    },
    {
      "epoch": 3.9948910997579996,
      "grad_norm": 16.543970108032227,
      "learning_rate": 1.114166168559474e-05,
      "loss": 0.1149,
      "step": 7430
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.19317428767681122,
      "learning_rate": 1.1111775254034669e-05,
      "loss": 0.0842,
      "step": 7440
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.8971359419120614,
      "eval_f1": 0.897395453436428,
      "eval_loss": 0.37778744101524353,
      "eval_runtime": 12.8748,
      "eval_samples_per_second": 1155.281,
      "eval_steps_per_second": 36.117,
      "step": 7440
    },
    {
      "epoch": 4.0053777897284215,
      "grad_norm": 3.8445472717285156,
      "learning_rate": 1.1081888822474596e-05,
      "loss": 0.0473,
      "step": 7450
    },
    {
      "epoch": 4.010755579456843,
      "grad_norm": 4.183395862579346,
      "learning_rate": 1.1052002390914525e-05,
      "loss": 0.0867,
      "step": 7460
    },
    {
      "epoch": 4.0161333691852645,
      "grad_norm": 14.9223051071167,
      "learning_rate": 1.1022115959354454e-05,
      "loss": 0.104,
      "step": 7470
    },
    {
      "epoch": 4.021511158913686,
      "grad_norm": 6.189014434814453,
      "learning_rate": 1.0992229527794382e-05,
      "loss": 0.1242,
      "step": 7480
    },
    {
      "epoch": 4.0268889486421084,
      "grad_norm": 0.440496563911438,
      "learning_rate": 1.0962343096234311e-05,
      "loss": 0.0684,
      "step": 7490
    },
    {
      "epoch": 4.03226673837053,
      "grad_norm": 8.436595916748047,
      "learning_rate": 1.0932456664674237e-05,
      "loss": 0.1189,
      "step": 7500
    },
    {
      "epoch": 4.0376445280989515,
      "grad_norm": 24.18157958984375,
      "learning_rate": 1.0902570233114166e-05,
      "loss": 0.1418,
      "step": 7510
    },
    {
      "epoch": 4.043022317827373,
      "grad_norm": 1.1602529287338257,
      "learning_rate": 1.0872683801554095e-05,
      "loss": 0.0846,
      "step": 7520
    },
    {
      "epoch": 4.0484001075557945,
      "grad_norm": 3.556020736694336,
      "learning_rate": 1.0842797369994023e-05,
      "loss": 0.0931,
      "step": 7530
    },
    {
      "epoch": 4.053777897284216,
      "grad_norm": 7.8691840171813965,
      "learning_rate": 1.0812910938433952e-05,
      "loss": 0.1252,
      "step": 7540
    },
    {
      "epoch": 4.0591556870126375,
      "grad_norm": 6.163845539093018,
      "learning_rate": 1.0783024506873881e-05,
      "loss": 0.1206,
      "step": 7550
    },
    {
      "epoch": 4.064533476741059,
      "grad_norm": 12.302651405334473,
      "learning_rate": 1.0753138075313807e-05,
      "loss": 0.1455,
      "step": 7560
    },
    {
      "epoch": 4.069911266469481,
      "grad_norm": 14.779557228088379,
      "learning_rate": 1.0723251643753736e-05,
      "loss": 0.0691,
      "step": 7570
    },
    {
      "epoch": 4.075289056197903,
      "grad_norm": 15.418404579162598,
      "learning_rate": 1.0693365212193663e-05,
      "loss": 0.1236,
      "step": 7580
    },
    {
      "epoch": 4.0806668459263244,
      "grad_norm": 13.44656753540039,
      "learning_rate": 1.0663478780633593e-05,
      "loss": 0.1045,
      "step": 7590
    },
    {
      "epoch": 4.086044635654746,
      "grad_norm": 5.721007347106934,
      "learning_rate": 1.0633592349073522e-05,
      "loss": 0.0798,
      "step": 7600
    },
    {
      "epoch": 4.0914224253831675,
      "grad_norm": 20.22269058227539,
      "learning_rate": 1.060370591751345e-05,
      "loss": 0.0639,
      "step": 7610
    },
    {
      "epoch": 4.096800215111589,
      "grad_norm": 13.998334884643555,
      "learning_rate": 1.0573819485953377e-05,
      "loss": 0.1406,
      "step": 7620
    },
    {
      "epoch": 4.1021780048400105,
      "grad_norm": 0.8427284955978394,
      "learning_rate": 1.0543933054393304e-05,
      "loss": 0.0769,
      "step": 7630
    },
    {
      "epoch": 4.107555794568432,
      "grad_norm": 9.72934627532959,
      "learning_rate": 1.0514046622833233e-05,
      "loss": 0.1833,
      "step": 7640
    },
    {
      "epoch": 4.112933584296854,
      "grad_norm": 26.65860939025879,
      "learning_rate": 1.0484160191273163e-05,
      "loss": 0.1045,
      "step": 7650
    },
    {
      "epoch": 4.118311374025276,
      "grad_norm": 17.05878448486328,
      "learning_rate": 1.045427375971309e-05,
      "loss": 0.0637,
      "step": 7660
    },
    {
      "epoch": 4.123689163753697,
      "grad_norm": 16.946706771850586,
      "learning_rate": 1.042438732815302e-05,
      "loss": 0.1291,
      "step": 7670
    },
    {
      "epoch": 4.129066953482119,
      "grad_norm": 8.835036277770996,
      "learning_rate": 1.0394500896592949e-05,
      "loss": 0.1259,
      "step": 7680
    },
    {
      "epoch": 4.1344447432105405,
      "grad_norm": 1.2522293329238892,
      "learning_rate": 1.0364614465032874e-05,
      "loss": 0.0775,
      "step": 7690
    },
    {
      "epoch": 4.139822532938962,
      "grad_norm": 18.982175827026367,
      "learning_rate": 1.0334728033472803e-05,
      "loss": 0.1051,
      "step": 7700
    },
    {
      "epoch": 4.1452003226673835,
      "grad_norm": 3.1766464710235596,
      "learning_rate": 1.0304841601912731e-05,
      "loss": 0.0711,
      "step": 7710
    },
    {
      "epoch": 4.150578112395805,
      "grad_norm": 16.793882369995117,
      "learning_rate": 1.027495517035266e-05,
      "loss": 0.1118,
      "step": 7720
    },
    {
      "epoch": 4.1559559021242265,
      "grad_norm": 1.199218988418579,
      "learning_rate": 1.024506873879259e-05,
      "loss": 0.1248,
      "step": 7730
    },
    {
      "epoch": 4.161333691852649,
      "grad_norm": 3.612717866897583,
      "learning_rate": 1.0215182307232517e-05,
      "loss": 0.0785,
      "step": 7740
    },
    {
      "epoch": 4.16671148158107,
      "grad_norm": 15.188602447509766,
      "learning_rate": 1.0185295875672444e-05,
      "loss": 0.1138,
      "step": 7750
    },
    {
      "epoch": 4.172089271309492,
      "grad_norm": 1.1833950281143188,
      "learning_rate": 1.0155409444112373e-05,
      "loss": 0.1342,
      "step": 7760
    },
    {
      "epoch": 4.177467061037913,
      "grad_norm": 0.6683157086372375,
      "learning_rate": 1.0125523012552301e-05,
      "loss": 0.0541,
      "step": 7770
    },
    {
      "epoch": 4.182844850766335,
      "grad_norm": 32.572566986083984,
      "learning_rate": 1.009563658099223e-05,
      "loss": 0.1741,
      "step": 7780
    },
    {
      "epoch": 4.1882226404947565,
      "grad_norm": 2.9954476356506348,
      "learning_rate": 1.0065750149432158e-05,
      "loss": 0.0942,
      "step": 7790
    },
    {
      "epoch": 4.193600430223178,
      "grad_norm": 2.543379306793213,
      "learning_rate": 1.0035863717872087e-05,
      "loss": 0.0588,
      "step": 7800
    },
    {
      "epoch": 4.1989782199515995,
      "grad_norm": 0.8210890889167786,
      "learning_rate": 1.0005977286312016e-05,
      "loss": 0.1158,
      "step": 7810
    },
    {
      "epoch": 4.204356009680022,
      "grad_norm": 18.180004119873047,
      "learning_rate": 9.976090854751942e-06,
      "loss": 0.0584,
      "step": 7820
    },
    {
      "epoch": 4.209733799408443,
      "grad_norm": 26.858125686645508,
      "learning_rate": 9.946204423191871e-06,
      "loss": 0.1004,
      "step": 7830
    },
    {
      "epoch": 4.215111589136865,
      "grad_norm": 13.3099365234375,
      "learning_rate": 9.916317991631798e-06,
      "loss": 0.082,
      "step": 7840
    },
    {
      "epoch": 4.220489378865286,
      "grad_norm": 0.5723838210105896,
      "learning_rate": 9.886431560071728e-06,
      "loss": 0.0998,
      "step": 7850
    },
    {
      "epoch": 4.225867168593708,
      "grad_norm": 7.171064853668213,
      "learning_rate": 9.856545128511657e-06,
      "loss": 0.1118,
      "step": 7860
    },
    {
      "epoch": 4.231244958322129,
      "grad_norm": 21.575822830200195,
      "learning_rate": 9.826658696951584e-06,
      "loss": 0.0908,
      "step": 7870
    },
    {
      "epoch": 4.236622748050551,
      "grad_norm": 0.2759731411933899,
      "learning_rate": 9.796772265391512e-06,
      "loss": 0.0838,
      "step": 7880
    },
    {
      "epoch": 4.2420005377789725,
      "grad_norm": 0.7264422178268433,
      "learning_rate": 9.766885833831441e-06,
      "loss": 0.0682,
      "step": 7890
    },
    {
      "epoch": 4.247378327507395,
      "grad_norm": 0.8808684349060059,
      "learning_rate": 9.736999402271368e-06,
      "loss": 0.1005,
      "step": 7900
    },
    {
      "epoch": 4.252756117235816,
      "grad_norm": 3.6107096672058105,
      "learning_rate": 9.707112970711298e-06,
      "loss": 0.1396,
      "step": 7910
    },
    {
      "epoch": 4.258133906964238,
      "grad_norm": 0.2720688581466675,
      "learning_rate": 9.677226539151225e-06,
      "loss": 0.085,
      "step": 7920
    },
    {
      "epoch": 4.263511696692659,
      "grad_norm": 0.48239558935165405,
      "learning_rate": 9.647340107591154e-06,
      "loss": 0.1291,
      "step": 7930
    },
    {
      "epoch": 4.268889486421081,
      "grad_norm": 43.11894607543945,
      "learning_rate": 9.617453676031083e-06,
      "loss": 0.1199,
      "step": 7940
    },
    {
      "epoch": 4.274267276149502,
      "grad_norm": 3.2200446128845215,
      "learning_rate": 9.58756724447101e-06,
      "loss": 0.155,
      "step": 7950
    },
    {
      "epoch": 4.279645065877924,
      "grad_norm": 2.9061903953552246,
      "learning_rate": 9.557680812910938e-06,
      "loss": 0.0897,
      "step": 7960
    },
    {
      "epoch": 4.285022855606345,
      "grad_norm": 1.381922721862793,
      "learning_rate": 9.527794381350868e-06,
      "loss": 0.0995,
      "step": 7970
    },
    {
      "epoch": 4.290400645334767,
      "grad_norm": 19.886247634887695,
      "learning_rate": 9.497907949790795e-06,
      "loss": 0.1582,
      "step": 7980
    },
    {
      "epoch": 4.295778435063189,
      "grad_norm": 9.130839347839355,
      "learning_rate": 9.468021518230724e-06,
      "loss": 0.0369,
      "step": 7990
    },
    {
      "epoch": 4.301156224791611,
      "grad_norm": 3.226677417755127,
      "learning_rate": 9.438135086670652e-06,
      "loss": 0.0911,
      "step": 8000
    },
    {
      "epoch": 4.306534014520032,
      "grad_norm": 0.7793240547180176,
      "learning_rate": 9.40824865511058e-06,
      "loss": 0.0991,
      "step": 8010
    },
    {
      "epoch": 4.311911804248454,
      "grad_norm": 18.880760192871094,
      "learning_rate": 9.378362223550508e-06,
      "loss": 0.0999,
      "step": 8020
    },
    {
      "epoch": 4.317289593976875,
      "grad_norm": Infinity,
      "learning_rate": 9.351464435146444e-06,
      "loss": 0.1044,
      "step": 8030
    },
    {
      "epoch": 4.322667383705297,
      "grad_norm": 2.251634120941162,
      "learning_rate": 9.321578003586372e-06,
      "loss": 0.0724,
      "step": 8040
    },
    {
      "epoch": 4.328045173433718,
      "grad_norm": 8.311739921569824,
      "learning_rate": 9.2916915720263e-06,
      "loss": 0.0856,
      "step": 8050
    },
    {
      "epoch": 4.333422963162141,
      "grad_norm": 3.0309793949127197,
      "learning_rate": 9.261805140466229e-06,
      "loss": 0.1254,
      "step": 8060
    },
    {
      "epoch": 4.338800752890562,
      "grad_norm": 0.9087314605712891,
      "learning_rate": 9.231918708906156e-06,
      "loss": 0.1134,
      "step": 8070
    },
    {
      "epoch": 4.344178542618984,
      "grad_norm": 2.846428632736206,
      "learning_rate": 9.202032277346085e-06,
      "loss": 0.1324,
      "step": 8080
    },
    {
      "epoch": 4.349556332347405,
      "grad_norm": 14.530524253845215,
      "learning_rate": 9.172145845786014e-06,
      "loss": 0.0931,
      "step": 8090
    },
    {
      "epoch": 4.354934122075827,
      "grad_norm": 0.285015344619751,
      "learning_rate": 9.142259414225942e-06,
      "loss": 0.075,
      "step": 8100
    },
    {
      "epoch": 4.360311911804248,
      "grad_norm": 18.754901885986328,
      "learning_rate": 9.112372982665871e-06,
      "loss": 0.1224,
      "step": 8110
    },
    {
      "epoch": 4.36568970153267,
      "grad_norm": 16.307008743286133,
      "learning_rate": 9.082486551105797e-06,
      "loss": 0.0795,
      "step": 8120
    },
    {
      "epoch": 4.371067491261091,
      "grad_norm": 0.9871559739112854,
      "learning_rate": 9.052600119545726e-06,
      "loss": 0.0847,
      "step": 8130
    },
    {
      "epoch": 4.376445280989513,
      "grad_norm": 1.8006995916366577,
      "learning_rate": 9.022713687985655e-06,
      "loss": 0.1047,
      "step": 8140
    },
    {
      "epoch": 4.381823070717935,
      "grad_norm": 32.98632049560547,
      "learning_rate": 8.992827256425583e-06,
      "loss": 0.0851,
      "step": 8150
    },
    {
      "epoch": 4.387200860446357,
      "grad_norm": 3.010756492614746,
      "learning_rate": 8.962940824865512e-06,
      "loss": 0.0656,
      "step": 8160
    },
    {
      "epoch": 4.392578650174778,
      "grad_norm": 13.875601768493652,
      "learning_rate": 8.933054393305441e-06,
      "loss": 0.1162,
      "step": 8170
    },
    {
      "epoch": 4.3979564399032,
      "grad_norm": 1.6521517038345337,
      "learning_rate": 8.903167961745367e-06,
      "loss": 0.0861,
      "step": 8180
    },
    {
      "epoch": 4.403334229631621,
      "grad_norm": 0.8635933995246887,
      "learning_rate": 8.873281530185296e-06,
      "loss": 0.0694,
      "step": 8190
    },
    {
      "epoch": 4.408712019360043,
      "grad_norm": 0.29963961243629456,
      "learning_rate": 8.843395098625224e-06,
      "loss": 0.125,
      "step": 8200
    },
    {
      "epoch": 4.414089809088464,
      "grad_norm": 7.278962135314941,
      "learning_rate": 8.813508667065153e-06,
      "loss": 0.0502,
      "step": 8210
    },
    {
      "epoch": 4.419467598816886,
      "grad_norm": 1.2187892198562622,
      "learning_rate": 8.783622235505082e-06,
      "loss": 0.0798,
      "step": 8220
    },
    {
      "epoch": 4.424845388545308,
      "grad_norm": 1.6595302820205688,
      "learning_rate": 8.75373580394501e-06,
      "loss": 0.0976,
      "step": 8230
    },
    {
      "epoch": 4.43022317827373,
      "grad_norm": 15.26343059539795,
      "learning_rate": 8.723849372384939e-06,
      "loss": 0.0872,
      "step": 8240
    },
    {
      "epoch": 4.435600968002151,
      "grad_norm": 7.00639533996582,
      "learning_rate": 8.693962940824864e-06,
      "loss": 0.1083,
      "step": 8250
    },
    {
      "epoch": 4.440978757730573,
      "grad_norm": 6.882448673248291,
      "learning_rate": 8.664076509264794e-06,
      "loss": 0.1271,
      "step": 8260
    },
    {
      "epoch": 4.446356547458994,
      "grad_norm": 5.319602966308594,
      "learning_rate": 8.634190077704723e-06,
      "loss": 0.0809,
      "step": 8270
    },
    {
      "epoch": 4.451734337187416,
      "grad_norm": 3.5320029258728027,
      "learning_rate": 8.60430364614465e-06,
      "loss": 0.0578,
      "step": 8280
    },
    {
      "epoch": 4.457112126915837,
      "grad_norm": 4.429020404815674,
      "learning_rate": 8.57441721458458e-06,
      "loss": 0.0432,
      "step": 8290
    },
    {
      "epoch": 4.462489916644259,
      "grad_norm": 4.936003684997559,
      "learning_rate": 8.544530783024509e-06,
      "loss": 0.1035,
      "step": 8300
    },
    {
      "epoch": 4.467867706372681,
      "grad_norm": 0.8103697299957275,
      "learning_rate": 8.514644351464434e-06,
      "loss": 0.1184,
      "step": 8310
    },
    {
      "epoch": 4.473245496101103,
      "grad_norm": 2.494964122772217,
      "learning_rate": 8.484757919904364e-06,
      "loss": 0.175,
      "step": 8320
    },
    {
      "epoch": 4.478623285829524,
      "grad_norm": 1.5005697011947632,
      "learning_rate": 8.454871488344291e-06,
      "loss": 0.1311,
      "step": 8330
    },
    {
      "epoch": 4.484001075557946,
      "grad_norm": 1.9445098638534546,
      "learning_rate": 8.42498505678422e-06,
      "loss": 0.1159,
      "step": 8340
    },
    {
      "epoch": 4.489378865286367,
      "grad_norm": 11.849225997924805,
      "learning_rate": 8.39509862522415e-06,
      "loss": 0.1559,
      "step": 8350
    },
    {
      "epoch": 4.494756655014789,
      "grad_norm": 2.261216640472412,
      "learning_rate": 8.365212193664077e-06,
      "loss": 0.0827,
      "step": 8360
    },
    {
      "epoch": 4.50013444474321,
      "grad_norm": 1.745995283126831,
      "learning_rate": 8.335325762104006e-06,
      "loss": 0.0939,
      "step": 8370
    },
    {
      "epoch": 4.505512234471632,
      "grad_norm": 1.5445107221603394,
      "learning_rate": 8.305439330543932e-06,
      "loss": 0.1087,
      "step": 8380
    },
    {
      "epoch": 4.510890024200053,
      "grad_norm": 5.280963897705078,
      "learning_rate": 8.275552898983861e-06,
      "loss": 0.064,
      "step": 8390
    },
    {
      "epoch": 4.516267813928476,
      "grad_norm": 22.809877395629883,
      "learning_rate": 8.24566646742379e-06,
      "loss": 0.1287,
      "step": 8400
    },
    {
      "epoch": 4.521645603656897,
      "grad_norm": 10.758199691772461,
      "learning_rate": 8.215780035863718e-06,
      "loss": 0.0826,
      "step": 8410
    },
    {
      "epoch": 4.527023393385319,
      "grad_norm": 0.602367103099823,
      "learning_rate": 8.185893604303647e-06,
      "loss": 0.0865,
      "step": 8420
    },
    {
      "epoch": 4.53240118311374,
      "grad_norm": 19.25715446472168,
      "learning_rate": 8.156007172743576e-06,
      "loss": 0.0971,
      "step": 8430
    },
    {
      "epoch": 4.537778972842162,
      "grad_norm": 5.923047065734863,
      "learning_rate": 8.126120741183502e-06,
      "loss": 0.0681,
      "step": 8440
    },
    {
      "epoch": 4.543156762570583,
      "grad_norm": 0.742443859577179,
      "learning_rate": 8.096234309623431e-06,
      "loss": 0.1284,
      "step": 8450
    },
    {
      "epoch": 4.548534552299005,
      "grad_norm": 12.674220085144043,
      "learning_rate": 8.066347878063358e-06,
      "loss": 0.1282,
      "step": 8460
    },
    {
      "epoch": 4.553912342027426,
      "grad_norm": 5.217801094055176,
      "learning_rate": 8.036461446503288e-06,
      "loss": 0.1026,
      "step": 8470
    },
    {
      "epoch": 4.559290131755848,
      "grad_norm": 0.0841665267944336,
      "learning_rate": 8.006575014943217e-06,
      "loss": 0.0824,
      "step": 8480
    },
    {
      "epoch": 4.56466792148427,
      "grad_norm": 0.5317903161048889,
      "learning_rate": 7.976688583383144e-06,
      "loss": 0.1199,
      "step": 8490
    },
    {
      "epoch": 4.570045711212692,
      "grad_norm": 1.1913989782333374,
      "learning_rate": 7.946802151823074e-06,
      "loss": 0.0792,
      "step": 8500
    },
    {
      "epoch": 4.575423500941113,
      "grad_norm": 0.32950910925865173,
      "learning_rate": 7.916915720263001e-06,
      "loss": 0.2063,
      "step": 8510
    },
    {
      "epoch": 4.580801290669535,
      "grad_norm": 9.68372917175293,
      "learning_rate": 7.887029288702928e-06,
      "loss": 0.0755,
      "step": 8520
    },
    {
      "epoch": 4.586179080397956,
      "grad_norm": 1.8647180795669556,
      "learning_rate": 7.857142857142858e-06,
      "loss": 0.0974,
      "step": 8530
    },
    {
      "epoch": 4.591556870126378,
      "grad_norm": 2.0736563205718994,
      "learning_rate": 7.827256425582785e-06,
      "loss": 0.0986,
      "step": 8540
    },
    {
      "epoch": 4.596934659854799,
      "grad_norm": 0.8616903424263,
      "learning_rate": 7.797369994022714e-06,
      "loss": 0.0893,
      "step": 8550
    },
    {
      "epoch": 4.602312449583222,
      "grad_norm": 18.582561492919922,
      "learning_rate": 7.767483562462644e-06,
      "loss": 0.0441,
      "step": 8560
    },
    {
      "epoch": 4.607690239311643,
      "grad_norm": 0.828085720539093,
      "learning_rate": 7.73759713090257e-06,
      "loss": 0.1108,
      "step": 8570
    },
    {
      "epoch": 4.613068029040065,
      "grad_norm": 23.119972229003906,
      "learning_rate": 7.707710699342498e-06,
      "loss": 0.1534,
      "step": 8580
    },
    {
      "epoch": 4.618445818768486,
      "grad_norm": 20.00420570373535,
      "learning_rate": 7.677824267782426e-06,
      "loss": 0.0992,
      "step": 8590
    },
    {
      "epoch": 4.623823608496908,
      "grad_norm": 33.081485748291016,
      "learning_rate": 7.647937836222355e-06,
      "loss": 0.1157,
      "step": 8600
    },
    {
      "epoch": 4.629201398225329,
      "grad_norm": 18.976238250732422,
      "learning_rate": 7.618051404662284e-06,
      "loss": 0.087,
      "step": 8610
    },
    {
      "epoch": 4.634579187953751,
      "grad_norm": 6.42959451675415,
      "learning_rate": 7.588164973102211e-06,
      "loss": 0.1051,
      "step": 8620
    },
    {
      "epoch": 4.639956977682172,
      "grad_norm": 1.1799890995025635,
      "learning_rate": 7.55827854154214e-06,
      "loss": 0.103,
      "step": 8630
    },
    {
      "epoch": 4.645334767410594,
      "grad_norm": 1.9117152690887451,
      "learning_rate": 7.528392109982069e-06,
      "loss": 0.0988,
      "step": 8640
    },
    {
      "epoch": 4.650712557139016,
      "grad_norm": 20.42855453491211,
      "learning_rate": 7.498505678421996e-06,
      "loss": 0.0954,
      "step": 8650
    },
    {
      "epoch": 4.656090346867438,
      "grad_norm": 3.4067752361297607,
      "learning_rate": 7.468619246861925e-06,
      "loss": 0.1133,
      "step": 8660
    },
    {
      "epoch": 4.661468136595859,
      "grad_norm": 10.513004302978516,
      "learning_rate": 7.4387328153018535e-06,
      "loss": 0.0862,
      "step": 8670
    },
    {
      "epoch": 4.666845926324281,
      "grad_norm": 0.6821030378341675,
      "learning_rate": 7.408846383741781e-06,
      "loss": 0.1004,
      "step": 8680
    },
    {
      "epoch": 4.672223716052702,
      "grad_norm": 1.4785704612731934,
      "learning_rate": 7.378959952181709e-06,
      "loss": 0.0538,
      "step": 8690
    },
    {
      "epoch": 4.677601505781124,
      "grad_norm": 8.579052925109863,
      "learning_rate": 7.3490735206216385e-06,
      "loss": 0.1113,
      "step": 8700
    },
    {
      "epoch": 4.682979295509545,
      "grad_norm": 24.171951293945312,
      "learning_rate": 7.319187089061567e-06,
      "loss": 0.0742,
      "step": 8710
    },
    {
      "epoch": 4.688357085237968,
      "grad_norm": 3.1232733726501465,
      "learning_rate": 7.289300657501494e-06,
      "loss": 0.0907,
      "step": 8720
    },
    {
      "epoch": 4.693734874966389,
      "grad_norm": 0.793946385383606,
      "learning_rate": 7.259414225941423e-06,
      "loss": 0.066,
      "step": 8730
    },
    {
      "epoch": 4.699112664694811,
      "grad_norm": 4.159336090087891,
      "learning_rate": 7.229527794381351e-06,
      "loss": 0.0796,
      "step": 8740
    },
    {
      "epoch": 4.704490454423232,
      "grad_norm": 0.8801496624946594,
      "learning_rate": 7.199641362821279e-06,
      "loss": 0.0713,
      "step": 8750
    },
    {
      "epoch": 4.709868244151654,
      "grad_norm": 3.1409928798675537,
      "learning_rate": 7.169754931261208e-06,
      "loss": 0.0719,
      "step": 8760
    },
    {
      "epoch": 4.715246033880075,
      "grad_norm": 8.49965763092041,
      "learning_rate": 7.139868499701136e-06,
      "loss": 0.0958,
      "step": 8770
    },
    {
      "epoch": 4.720623823608497,
      "grad_norm": 0.7842882871627808,
      "learning_rate": 7.1099820681410635e-06,
      "loss": 0.0975,
      "step": 8780
    },
    {
      "epoch": 4.726001613336918,
      "grad_norm": 8.879566192626953,
      "learning_rate": 7.080095636580993e-06,
      "loss": 0.1208,
      "step": 8790
    },
    {
      "epoch": 4.73137940306534,
      "grad_norm": 19.561119079589844,
      "learning_rate": 7.050209205020921e-06,
      "loss": 0.1421,
      "step": 8800
    },
    {
      "epoch": 4.736757192793762,
      "grad_norm": 29.0784854888916,
      "learning_rate": 7.0203227734608485e-06,
      "loss": 0.1028,
      "step": 8810
    },
    {
      "epoch": 4.742134982522184,
      "grad_norm": 0.3678627610206604,
      "learning_rate": 6.990436341900777e-06,
      "loss": 0.0983,
      "step": 8820
    },
    {
      "epoch": 4.747512772250605,
      "grad_norm": 12.31678581237793,
      "learning_rate": 6.960549910340706e-06,
      "loss": 0.1129,
      "step": 8830
    },
    {
      "epoch": 4.752890561979027,
      "grad_norm": 5.450401782989502,
      "learning_rate": 6.930663478780634e-06,
      "loss": 0.1584,
      "step": 8840
    },
    {
      "epoch": 4.758268351707448,
      "grad_norm": 1.2497307062149048,
      "learning_rate": 6.900777047220562e-06,
      "loss": 0.1043,
      "step": 8850
    },
    {
      "epoch": 4.76364614143587,
      "grad_norm": 0.5785452127456665,
      "learning_rate": 6.87089061566049e-06,
      "loss": 0.0733,
      "step": 8860
    },
    {
      "epoch": 4.769023931164291,
      "grad_norm": 0.3783109188079834,
      "learning_rate": 6.841004184100419e-06,
      "loss": 0.0818,
      "step": 8870
    },
    {
      "epoch": 4.774401720892713,
      "grad_norm": 22.032827377319336,
      "learning_rate": 6.811117752540347e-06,
      "loss": 0.1106,
      "step": 8880
    },
    {
      "epoch": 4.779779510621134,
      "grad_norm": 12.721832275390625,
      "learning_rate": 6.781231320980275e-06,
      "loss": 0.0428,
      "step": 8890
    },
    {
      "epoch": 4.785157300349557,
      "grad_norm": 8.348679542541504,
      "learning_rate": 6.7513448894202035e-06,
      "loss": 0.1244,
      "step": 8900
    },
    {
      "epoch": 4.790535090077978,
      "grad_norm": 2.63442063331604,
      "learning_rate": 6.721458457860132e-06,
      "loss": 0.0733,
      "step": 8910
    },
    {
      "epoch": 4.7959128798064,
      "grad_norm": 2.320385456085205,
      "learning_rate": 6.69157202630006e-06,
      "loss": 0.0796,
      "step": 8920
    },
    {
      "epoch": 4.801290669534821,
      "grad_norm": 11.68549919128418,
      "learning_rate": 6.6616855947399885e-06,
      "loss": 0.1269,
      "step": 8930
    },
    {
      "epoch": 4.806668459263243,
      "grad_norm": 7.4719767570495605,
      "learning_rate": 6.631799163179916e-06,
      "loss": 0.1365,
      "step": 8940
    },
    {
      "epoch": 4.812046248991664,
      "grad_norm": 15.339153289794922,
      "learning_rate": 6.601912731619844e-06,
      "loss": 0.1315,
      "step": 8950
    },
    {
      "epoch": 4.817424038720086,
      "grad_norm": 16.340545654296875,
      "learning_rate": 6.5720263000597735e-06,
      "loss": 0.0938,
      "step": 8960
    },
    {
      "epoch": 4.822801828448508,
      "grad_norm": 6.7510504722595215,
      "learning_rate": 6.542139868499701e-06,
      "loss": 0.1328,
      "step": 8970
    },
    {
      "epoch": 4.82817961817693,
      "grad_norm": 15.31383991241455,
      "learning_rate": 6.512253436939629e-06,
      "loss": 0.1305,
      "step": 8980
    },
    {
      "epoch": 4.833557407905351,
      "grad_norm": 14.35411548614502,
      "learning_rate": 6.482367005379558e-06,
      "loss": 0.0561,
      "step": 8990
    },
    {
      "epoch": 4.838935197633773,
      "grad_norm": 3.5230321884155273,
      "learning_rate": 6.452480573819487e-06,
      "loss": 0.1181,
      "step": 9000
    },
    {
      "epoch": 4.844312987362194,
      "grad_norm": 7.097290992736816,
      "learning_rate": 6.422594142259414e-06,
      "loss": 0.1264,
      "step": 9010
    },
    {
      "epoch": 4.849690777090616,
      "grad_norm": 19.410093307495117,
      "learning_rate": 6.392707710699343e-06,
      "loss": 0.1075,
      "step": 9020
    },
    {
      "epoch": 4.855068566819037,
      "grad_norm": 8.7008695602417,
      "learning_rate": 6.362821279139271e-06,
      "loss": 0.0809,
      "step": 9030
    },
    {
      "epoch": 4.860446356547459,
      "grad_norm": 0.23914065957069397,
      "learning_rate": 6.332934847579199e-06,
      "loss": 0.0544,
      "step": 9040
    },
    {
      "epoch": 4.86582414627588,
      "grad_norm": 9.864187240600586,
      "learning_rate": 6.303048416019128e-06,
      "loss": 0.0822,
      "step": 9050
    },
    {
      "epoch": 4.871201936004303,
      "grad_norm": 0.223275825381279,
      "learning_rate": 6.273161984459056e-06,
      "loss": 0.0731,
      "step": 9060
    },
    {
      "epoch": 4.876579725732724,
      "grad_norm": 0.4076783061027527,
      "learning_rate": 6.2432755528989834e-06,
      "loss": 0.0753,
      "step": 9070
    },
    {
      "epoch": 4.881957515461146,
      "grad_norm": 23.160518646240234,
      "learning_rate": 6.213389121338913e-06,
      "loss": 0.0858,
      "step": 9080
    },
    {
      "epoch": 4.887335305189567,
      "grad_norm": 0.6018364429473877,
      "learning_rate": 6.183502689778841e-06,
      "loss": 0.1518,
      "step": 9090
    },
    {
      "epoch": 4.892713094917989,
      "grad_norm": 0.09206844121217728,
      "learning_rate": 6.1536162582187684e-06,
      "loss": 0.1319,
      "step": 9100
    },
    {
      "epoch": 4.89809088464641,
      "grad_norm": 18.111427307128906,
      "learning_rate": 6.123729826658697e-06,
      "loss": 0.0705,
      "step": 9110
    },
    {
      "epoch": 4.903468674374832,
      "grad_norm": 13.895699501037598,
      "learning_rate": 6.093843395098625e-06,
      "loss": 0.0774,
      "step": 9120
    },
    {
      "epoch": 4.908846464103253,
      "grad_norm": 0.44040369987487793,
      "learning_rate": 6.063956963538554e-06,
      "loss": 0.0742,
      "step": 9130
    },
    {
      "epoch": 4.914224253831675,
      "grad_norm": 3.443046808242798,
      "learning_rate": 6.034070531978482e-06,
      "loss": 0.154,
      "step": 9140
    },
    {
      "epoch": 4.919602043560097,
      "grad_norm": 2.337130069732666,
      "learning_rate": 6.00418410041841e-06,
      "loss": 0.1454,
      "step": 9150
    },
    {
      "epoch": 4.924979833288519,
      "grad_norm": 24.60991859436035,
      "learning_rate": 5.9742976688583384e-06,
      "loss": 0.0755,
      "step": 9160
    },
    {
      "epoch": 4.93035762301694,
      "grad_norm": 29.04473304748535,
      "learning_rate": 5.944411237298267e-06,
      "loss": 0.0925,
      "step": 9170
    },
    {
      "epoch": 4.935735412745362,
      "grad_norm": 0.8472703099250793,
      "learning_rate": 5.914524805738195e-06,
      "loss": 0.1244,
      "step": 9180
    },
    {
      "epoch": 4.941113202473783,
      "grad_norm": 1.306565523147583,
      "learning_rate": 5.8846383741781234e-06,
      "loss": 0.0898,
      "step": 9190
    },
    {
      "epoch": 4.946490992202205,
      "grad_norm": 19.57599449157715,
      "learning_rate": 5.854751942618051e-06,
      "loss": 0.0873,
      "step": 9200
    },
    {
      "epoch": 4.951868781930626,
      "grad_norm": 3.860403537750244,
      "learning_rate": 5.82486551105798e-06,
      "loss": 0.0945,
      "step": 9210
    },
    {
      "epoch": 4.957246571659049,
      "grad_norm": 13.858181953430176,
      "learning_rate": 5.7949790794979084e-06,
      "loss": 0.0786,
      "step": 9220
    },
    {
      "epoch": 4.96262436138747,
      "grad_norm": 26.96500015258789,
      "learning_rate": 5.765092647937836e-06,
      "loss": 0.1273,
      "step": 9230
    },
    {
      "epoch": 4.968002151115892,
      "grad_norm": 1.490039587020874,
      "learning_rate": 5.735206216377764e-06,
      "loss": 0.0728,
      "step": 9240
    },
    {
      "epoch": 4.973379940844313,
      "grad_norm": 14.902436256408691,
      "learning_rate": 5.7053197848176934e-06,
      "loss": 0.1354,
      "step": 9250
    },
    {
      "epoch": 4.978757730572735,
      "grad_norm": 13.615157127380371,
      "learning_rate": 5.675433353257622e-06,
      "loss": 0.1137,
      "step": 9260
    },
    {
      "epoch": 4.984135520301156,
      "grad_norm": 8.28601360321045,
      "learning_rate": 5.645546921697549e-06,
      "loss": 0.0778,
      "step": 9270
    },
    {
      "epoch": 4.989513310029578,
      "grad_norm": 0.3124845325946808,
      "learning_rate": 5.615660490137478e-06,
      "loss": 0.0844,
      "step": 9280
    },
    {
      "epoch": 4.994891099757999,
      "grad_norm": 0.12167898565530777,
      "learning_rate": 5.585774058577406e-06,
      "loss": 0.0597,
      "step": 9290
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.005419720895588398,
      "learning_rate": 5.555887627017334e-06,
      "loss": 0.0864,
      "step": 9300
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9034556945004706,
      "eval_f1": 0.9033841360345001,
      "eval_loss": 0.40252044796943665,
      "eval_runtime": 12.9043,
      "eval_samples_per_second": 1152.641,
      "eval_steps_per_second": 36.035,
      "step": 9300
    }
  ],
  "logging_steps": 10,
  "max_steps": 11154,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.001
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9851620636354560.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
